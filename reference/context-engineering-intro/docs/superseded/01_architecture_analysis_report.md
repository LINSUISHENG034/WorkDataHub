> Note: This document is superseded by `README.md` (Developer Quickstart) and `ROADMAP.md`. It is preserved for historical context. For current plan/status see `ROADMAP.md`.

<architectural_proposal>
    <as_is_analysis>
        **1. 核心领域与职责:**
        遗留的 `annuity_hub` 应用本质上是一个单体的ETL（提取、转换、加载）管道，其核心职责包括：
        *   **数据源抓取 (`crawler`):** 从不同来源（文件系统、数据库等）获取原始数据文件。
        *   **数据清洗与转换 (`data_handler`):** 这是系统的核心，包含了针对多种不同格式的Excel/CSV文件的复杂业务逻辑，用于数据标准化、验证和转换。
        *   **数据持久化 (`database_operations`):** 将处理后的数据加载到MySQL和MongoDB中。
        *   **配置管理 (`config_manager`):** 提供对系统配置的访问，但实现方式混乱。

        **2. 关键架构缺陷与技术债分析:**
        结合两份分析报告，我们从定性和定量两个维度对系统的技术健康状况进行全面评估。

        ***2.1. 核心架构缺陷 (定性分析)***
        *   **单体巨石结构 (Monolithic Architecture):** 所有功能高度集中，`main.py` 承载了完整的ETL流程控制，而 `data_cleaner.py` 文件本身就是一个“内部单体”，包含了超过20种不同业务规则的实现，违反单一职责原则，极难维护和扩展。
        *   **严重耦合 (Tight Coupling):** 业务逻辑、数据处理流程和基础设施（数据库、文件系统）之间存在直接导入依赖，缺乏抽象层。`DataProcessor` 类是问题的集中体现，它同时承担了流程编排、状态管理和数据库交互的职责。
        *   **不可测试的代码 (Untestable Code):** 由于缺乏抽象、依赖注入和关注点分离，几乎所有核心逻辑都无法进行有效的单元测试。工厂模式的滥用和静态依赖使得Mock测试异常困难。
        *   **脆弱的数据处理:**
            *   **非原子性操作:** 系统采用“先删后插”的更新策略，且跨数据库操作缺乏统一的事务管理，在导入失败时极有可能导致数据永久丢失。
            *   **性能瓶颈:** 大文件处理采用全内存加载模式，存在明显的内存溢出风险。
        *   **混乱的配置管理:**
            *   **硬编码安全风险:** 存在明文密码和认证信息，且缺乏开发/测试/生产环境的配置隔离。
            *   **配置分散:** 业务映射规则散布在代码和数据库中，难以进行版本控制和原子化部署。

        ***2.2. 技术债与风险评估 (定量分析)***
        新报告提供了更量化的视角，明确了技术债的严重性和业务影响。

        **代码质量度量:**
        | 指标 | 当前状态 | 目标状态 | 改进优先级 |
        |---|---|---|---|
        | **代码覆盖率** | < 10% | > 80% | **P1** |
        | **模块耦合度** | 高 (直接导入) | 低 (接口解耦) | **P1** |
        | **配置外部化** | 0% | 100% | **P0** |
        | **单一职责遵守** | 低 | 高 | **P1** |

        **业务连续性风险:**
        *   **高风险项:**
            *   **数据一致性:** 缺乏事务管理，重构和运行期间都可能导致数据不一致。
            *   **系统可用性:** 单点故障风险高，任一组件故障将导致整体系统中断。
            *   **安全合规:** 硬编码凭据存在严重的安全审计风险。
        *   **中风险项:**
            *   **开发效率:** 紧耦合架构导致开发和维护成本持续上升，无法快速响应业务变化。
            *   **系统扩展性:** 无法适应业务数据量的快速增长需求。

        **3. 初步构想评估:**
        `BaseInfo.md` 中提出的初步构想质量非常高，展现了清晰的现代化架构思维。
        *   **前景广阔的方面:**
            *   **分层架构:** 提出的“流程控制层”、“数据处理层”、“存储层”等分层模型是解决当前耦合问题的正确方向。
            *   **策略模式:** 使用策略模式来解耦不同的ETL流程（`etl_strategy.py`, `validation_strategy.py`）是绝佳的设计，可以极大地提高系统的灵活性和可扩展性。
            *   **配置驱动:** 将Schema、依赖关系和业务规则外部化到配置文件中，是解决硬编码问题的关键。
            *   **依赖感知与错误处理:** 提出的依赖拓扑排序和错误处理漏斗概念，是构建健壮数据管道的核心要素。
        *   **需要完善的方面:**
            *   草案中的组件划分仍然偏向技术实现。在最终设计中，我们应更多地从**业务领域**的角度来划分模块（例如，一个模块负责处理“年金业绩”相关的所有数据源，而不是一个通用的“清洗器”）。
            *   需要更明确地定义各层之间的“契约”（Interfaces/Protocols），以强制实现依赖倒置原则。

    </as_is_analysis>

    <to_be_architecture_vision>
        **1. 高层架构概念:**
        提议的架构是一个**声明式的、由领域驱动的、事件触发的**数据处理平台。它将遗留的单体管道分解为一系列高内聚、低耦合的自治服务。整个流程由一个中央工作流编排器根据外部配置文件动态装配和执行，确保了系统的可观测性、可恢复性和可扩展性。

        **2. 核心组件与职责:**
        *   **工作流编排器 (Workflow Orchestrator):** (例如: Dagster, Airflow)
            *   **职责:** 读取声明式的管道定义（YAML/Python配置），根据定义的依赖关系（如 `BaseInfo.md` 中描述的拓扑排序）调度任务，并负责任务的重试、日志记录和监控。它将完全取代 `main.py` 的功能。
        *   **数据源连接器 (DataSource Connector):**
            *   **职责:** 负责从各种外部系统（文件、API、数据库）获取原始数据。每个连接器都是一个独立的、可配置的模块。
        *   **领域处理服务 (Domain Processing Services):**
            *   **职责:** 这是新架构的核心。我们将不再有单一的 `data_cleaner.py`，而是根据业务领域（例如：`AnnuityPerformanceService`, `HealthCoverageService`）创建独立的、可测试的Python包。每个服务都包含自己的验证、转换和业务逻辑，并以纯函数的形式实现，与基础设施完全解耦。
        *   **数据验证引擎 (Data Validation Engine):**
            *   **职责:** 基于 Pydantic 或类似框架，根据外部定义的JSON Schema对进入和流出领域服务的数据进行严格的结构和类型校验。
        *   **数据仓库/湖仓 (Data Warehouse / Lakehouse):**
            *   **职责:** 作为所有处理后数据的统一、可靠的存储目的地。它将取代目前直接写入生产MySQL/MongoDB的模式。所有写入操作都将是原子性的（Append-only 或 Merge）。
        *   **数据集市层 (Data Mart Layer):**
            *   **职责:** 在数据仓库之上，构建面向特定业务应用（如报表、API）的、经过聚合和优化的数据集。这使得下游应用与核心ETL过程解耦。

        **3. 数据流转说明:**
        1.  **触发:** 工作流编排器按计划或由外部事件（如新文件到达）触发一个工作流。
        2.  **提取:** 编排器调用相应的“数据源连接器”，将原始数据加载到临时存储区。
        3.  **验证 & 转换:** 编排器按顺序调用一个或多个“领域处理服务”。每个服务消费上一步的输出，执行自己的业务逻辑，并产出经过清洗和丰富的标准化数据。每一步的输入和输出都由“数据验证引擎”进行强制校验。
        4.  **加载:** 最后一个领域服务将最终处理完成的数据加载到“数据仓库”的暂存区（Staging Area）。
        5.  **原子化提交:** 在所有数据加载到暂存区后，执行一个原子性的 `MERGE` 或 `INSERT OVERWRITE` 操作，将数据发布到数据仓库的核心表中。
        6.  **发布:** 数据仓库中的数据更新后，触发下游的“数据集市层”的更新任务。

    </to_be_architecture_vision>

    <strategic_recommendations_and_roadmap>
        **1. 关键技术栈建议:**
        *   **语言:** Python 3.10+ (利用其强大的类型提示系统)。
        *   **核心处理库:** Pandas / Polars (Polars 在大规模数据集上性能更优)。
        *   **数据校验:** Pydantic (用于强制的数据契约)。
        *   **工作流编排器:** **Dagster** (推荐，因为它提供了强大的数据资产目录和本地开发体验) 或 Airflow。
        *   **数据存储:** **PostgreSQL** (作为健壮的数据仓库起点) 或云原生方案如 Snowflake / BigQuery / Databricks。
        *   **测试框架:** Pytest。
        *   **CI/CD:** GitHub Actions / Jenkins。

        **2. 里程碑驱动的重构路线图:**
        我们采用以目标和里程碑为导向的路线图，取代传统的时间预估，以确保进度评估的客观性和准确性。
        *   **里程碑一: 核心平台就绪 (Core Platform Ready)**
            *   **交付成果:** 一个功能完备、可测试、可部署的基础平台。
            *   **验收标准:**
                1.  工作流编排器（Dagster）已部署，并能成功运行一个“Hello World”级别的示例管道。
                2.  数据仓库（PostgreSQL）核心Schema已应用，CI/CD流水线中包含的连接性测试通过。
                3.  CI/CD流水线已建立，能够对代码提交自动执行代码质量检查、依赖扫描和单元测试。
        *   **里程碑二: 领域逻辑全覆盖 (Full Domain Logic Coverage)**
            *   **交付成果:** 所有遗留业务逻辑均已重构为独立的、高质量的领域服务。
            *   **验收标准:**
                1.  所有源自 `data_cleaner.py` 的业务逻辑均已重构为独立的、遵循单一职责原则的领域处理服务。
                2.  每个领域服务都拥有清晰的数据契约（Pydantic模型），并有对应的单元测试，代码覆盖率达到90%以上。
        *   **里程碑三: 端到端管道验证通过 (End-to-End Pipeline Validated)**
            *   **交付成果:** 一个完整、可靠、可观测的端到端数据处理管道。
            *   **验收标准:**
                1.  所有领域服务已成功集成至工作流编排器，形成完整的ETL工作流。
                2.  已使用全量历史输入文件对新旧两个系统进行批量处理，新系统输出的数据与旧系统输出的数据比对结果100%一致。
                3.  已建立关键数据质量指标（例如：记录数、关键字段空值率）的自动化监控和警报。
        *   **里程碑四: 项目交付 (Project Handover)**
            *   **交付成果:** 一个可供下游团队接管和维护的现代化数据平台。
            *   **验收标准:**
                1.  新系统已成功部署到最终的目标环境。
                2.  已交付完整的技术文档，包括最终架构图、服务接口说明和部署运维手册。
                3.  遗留代码库 `legacy/annuity_hub` 已被正式归档。

        **3. 交付原则与近期行动计划:**
        为了确保重构过程的成功，我们不仅需要一个宏观的路线图，还需要明确的交付原则和具体、可执行的近期步骤。

        ***3.1. 核心交付与验收原则***
        每个里程碑的交付物都必须遵循以下标准，以确保高质量的产出：
        *   **可测试性 (Testability):** 每个组件都必须具备独立的、自动化的单元测试和集成测试。
        *   **可观测性 (Observability):** 系统的关键性能指标（如处理时长、内存消耗）和业务指标（如记录数、空值率）都必须有相应的监控和告警。
        *   **可扩展性 (Scalability):** 新增数据源或处理逻辑应主要通过配置驱动，而非大规模代码修改。
        *   **可维护性 (Maintainability):** 代码结构清晰，文档完整，遵循SOLID原则。

        ***3.2. 近期关键行动 (Immediate Priorities)***
        在全面启动里程碑一之前，必须先完成一个 **“里程碑零”**，以消除当前最关键的风险，为后续开发奠定坚实基础。

        **🎯 里程碑零: 建立安全与质量基线**
        *   **目标:** 消除关键安全风险，建立项目的自动化质量保障体系。
        *   **关键行动:**
            1.  **安全风险消除:** 将所有硬编码的凭据（数据库密码、API密钥等）迁移到环境变量或专用的密钥管理服务中。
            2.  **建立测试基线:** 为当前系统最核心的一条数据处理路径，建立一个端到端的集成测试。这个测试暂时不需要关心内部实现，只需验证“给定输入文件，得到预期的数据库输出”。
            3.  **搭建CI/CD基础:** 建立一个基础的持续集成流水线，能够自动运行上述的端到端测试、代码风格检查和依赖安全扫描。
        *   **✅ 完成标准:**
            *   代码库中无可寻的明文凭据。
            *   核心流程的端到端测试在CI环境中稳定通过。
            *   基础的CI流水线已成功运行，并与代码仓库集成。
    </strategic_recommendations_and_roadmap>
</architectural_proposal>
