name: "P-023: Cleansing Framework Hardening (KISS/YAGNI) with Minimal Domain Changes"
description: |

## Purpose
Strengthen numeric cleansing and input header normalization to remove cross-domain duplication and align with legacy behavior, while keeping business-specific logic in domain or the future Mapping Service.

## Core Principles
1. **Context is King**: Include ALL necessary documentation, examples, and caveats
2. **Validation Loops**: Provide executable tests/lints the AI can run and fix
3. **Information Dense**: Use keywords and patterns from the codebase
4. **Progressive Success**: Start simple, validate, then enhance
5. **Global rules**: Be sure to follow all rules in CLAUDE.md

---

## Goal
Enhance the shared cleansing framework to support negative percentages, full-width Unicode characters (％), Excel header normalization, and annuity domain ^F prefix stripping while maintaining API stability and following KISS/YAGNI principles.

## Why
- **Business value**: Eliminates cross-domain duplication in data cleansing logic
- **Integration**: Aligns with legacy behavior without over-engineering
- **Problems solved**: Fixes percentage conversion edge cases, header formatting issues, and domain-specific data quirks

## What
Minimal enhancements to existing cleansing framework:
- Support negative percentages and full-width percent sign (％) in numeric rules
- Normalize Excel header strings by removing newlines and tabs
- Strip ^F prefix from 组合代码 in annuity domain
- Maintain public cleansing API stability

### Success Criteria
- [ ] "-5%" → Decimal("-0.050000") for rate fields; "12.3％" equals "12.3%" result
- [ ] Numeric values in rate fields: only `abs(value) > 1` are treated as percentage inputs
- [ ] Non-rate numeric fields do not get percentage conversion  
- [ ] Currency/formatting-only strings become `None` after null/currency normalization
- [ ] ExcelReader returns headers without `\n` or `\t`; `project_columns` no longer drops columns
- [ ] Annuity `组合代码` no longer contains leading `F` when present
- [ ] All existing tests remain green; new targeted tests pass

## All Needed Context

### Documentation & References
```yaml
# MUST READ - Include these in your context window
- url: https://docs.pydantic.dev/2.7/concepts/validators/
  why: Pydantic v2 field validator patterns, mode="before" vs mode="after"
  
- file: INITIAL.md
  why: Complete requirements specification and acceptance criteria
  
- file: src/work_data_hub/cleansing/rules/numeric_rules.py
  why: Current implementation patterns for comprehensive_decimal_cleaning and handle_percentage_conversion (lines 67-96, 175-236)
  
- file: src/work_data_hub/io/readers/excel_reader.py
  why: ExcelReader._dataframe_to_rows method for header normalization (lines 182-234)
  
- file: src/work_data_hub/domain/annuity_performance/service.py
  why: _extract_plan_code function for ^F prefix stripping (lines 365-372)
  
- file: tests/unit/test_cleansing_framework.py
  why: Existing test patterns for decimal cleaning assertions and Pydantic integration
  
- file: tests/io/test_excel_reader.py
  why: ExcelReader test patterns, especially header cleaning tests (lines 274-294)
```

### Implementation-Facing Research Notes
Purpose: Consolidate external research into actionable, implementation-facing notes to avoid duplicate searching and reduce information drift.

```yaml
sources:
  - url: https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize
    section: NFKC normalization
    why: Full-width character normalization for percentage signs
    type: docs

tldr:
  - Full-width percent sign (％) has Unicode code point U+FF05 vs regular % at U+0025
  - Use unicodedata.normalize('NFKC', text) to convert full-width to half-width ASCII equivalents
  - NFKC aggressively maps compatibility characters to canonical forms
  - Apply normalization before string processing to handle mixed width characters
  - Example: normalize_text('１００％') → '100%'

setup_commands:
  - "import unicodedata  # built-in Python module, no installation needed"

api_decisions:
  - name: handle_percentage_conversion enhancement
    choice: Add unicodedata.normalize('NFKC', value) before percentage processing
    rationale: Handles both % and ％ transparently while preserving existing logic

  - name: numeric percentage logic change
    choice: Change from "1 < value <= 100" to "abs(value) > 1" 
    rationale: Support negative percentages while maintaining rate field detection

  - name: header normalization location
    choice: ExcelReader._dataframe_to_rows method in column cleaning section
    rationale: Handle at data ingestion point to prevent downstream column mismatch issues

versions:
  - library: unicodedata
    constraint: "built-in"
    compatibility: Python 3.11+, no external dependencies

pitfalls_and_mitigations:
  - issue: Unicode normalization can change string length and content unexpectedly
    mitigation: Apply normalization consistently and test with mixed-width input

  - issue: Percentage logic change might affect non-rate fields  
    mitigation: Only apply to rate fields identified by field_name patterns

  - issue: ^F prefix might be legitimate data in some contexts
    mitigation: Strip only when field is specifically 组合代码 and starts with "F"

open_questions:
  - Should ^F stripping be case-sensitive or handle "f" prefix as well?
  - Are there other full-width characters beyond % that need normalization?
```

### Current Codebase tree (relevant sections)
```bash
src/work_data_hub/
  cleansing/
    rules/numeric_rules.py              # Lines 67-96: handle_percentage_conversion
                                        # Lines 175-236: comprehensive_decimal_cleaning
    integrations/pydantic_adapter.py    # Pydantic decorator (no API change needed)
  io/readers/excel_reader.py            # Lines 182-234: _dataframe_to_rows method
  domain/
    annuity_performance/
      service.py                        # Lines 365-372: _extract_plan_code function
      models.py                         # Line 61: 组合代码 field definition
tests/
  unit/test_cleansing_framework.py     # Existing test patterns to mirror
  io/test_excel_reader.py              # Header normalization test patterns
  domain/annuity_performance/test_service.py  # Domain service test patterns
```

### Known Gotchas of our codebase & Library Quirks
```python
# CRITICAL: Project uses Pydantic v2 with field_validator(..., mode="before")
# CRITICAL: Chinese field names in validators (e.g., "当期收益率", "组合代码")
# CRITICAL: Full-width percent sign ％ frequently appears in Excel data
# CRITICAL: Numeric percent heuristics only for rate fields when abs(value) > 1
# CRITICAL: Quantization uses ROUND_HALF_UP with precision from precision_config
# CRITICAL: Use rg for search, avoid grep/find commands
# CRITICAL: ExcelReader column cleaning happens before "Unnamed: n" handling
```

## Implementation Blueprint

### Data models and structure
No schema changes required. Both trustee and annuity models already call the shared numeric pipeline via `@decimal_fields_cleaner` decorator.

```python
# Public API remains unchanged
def comprehensive_decimal_cleaning(
    value: Any,
    field_name: str = "",
    precision: int | None = None,
    handle_percentage: bool = True,
    precision_config: Optional[Dict[str, int]] = None,
) -> Optional[Decimal]:
    # Enhanced implementation supports negative % and full-width characters
```

### List of tasks to be completed to fulfill the PRP in the order they should be completed

```yaml
Task 1: Enhance numeric rules for full-width characters and negative percentages
MODIFY src/work_data_hub/cleansing/rules/numeric_rules.py:
  - FIND function: handle_percentage_conversion (lines 67-96)
  - ADD import: "import unicodedata" at top of file
  - INJECT Unicode normalization before percentage processing
  - MODIFY numeric percentage logic from "1 < value <= 100" to "abs(value) > 1"
  - PRESERVE existing string percentage handling
  - KEEP all existing function signatures and return types

Task 2: Add ExcelReader header normalization
MODIFY src/work_data_hub/io/readers/excel_reader.py:
  - FIND method: _dataframe_to_rows (lines 182-234)
  - LOCATE column cleaning section around lines 188-196
  - INJECT .replace("\n", "").replace("\t", "") in column name cleaning
  - PRESERVE existing "Unnamed: n" column handling
  - MAINTAIN all existing data type conversions

Task 3: Add annuity domain ^F prefix stripping  
MODIFY src/work_data_hub/domain/annuity_performance/service.py:
  - FIND function: _extract_plan_code (lines 365-372)
  - MODIFY to strip "F" prefix from 组合代码 when present
  - PRESERVE existing plan code extraction logic
  - KEEP error handling and logging patterns

Task 4: Add comprehensive test coverage
CREATE tests for negative percentages:
  - MIRROR pattern from: tests/unit/test_cleansing_framework.py (lines 47-64)
  - ADD test cases for "-5%", "12.3％", negative numeric percentages
  - VERIFY abs(value) > 1 logic for rate vs non-rate fields

CREATE tests for header normalization:
  - MIRROR pattern from: tests/io/test_excel_reader.py (lines 274-294)
  - ADD test cases for headers with \n and \t characters
  - VERIFY project_columns no longer drops malformed columns

CREATE tests for annuity ^F stripping:
  - MIRROR pattern from: tests/domain/annuity_performance/test_service.py
  - ADD test cases for 组合代码 with and without "F" prefix
  - VERIFY legitimate "F" values are not stripped incorrectly
```

### Per task pseudocode

```python
# Task 1: Enhanced handle_percentage_conversion
import unicodedata

def handle_percentage_conversion(value: Any, field_name: str = "") -> Union[float, str]:
    # NEW: Normalize full-width characters first
    if isinstance(value, str):
        value = unicodedata.normalize('NFKC', value)
    
    # EXISTING: String percentage handling (now supports ％ after normalization)
    if isinstance(value, str) and "%" in value:
        try:
            numeric_part = value.replace("%", "").strip()
            return float(numeric_part) / 100.0
        except ValueError:
            raise ValueError(f"Invalid percentage format: {value}")

    # MODIFIED: Numeric percentage handling for rate fields
    if isinstance(value, (int, float)) and ("收益率" in field_name or "rate" in field_name.lower()):
        # CHANGED: from "1 < value <= 100" to "abs(value) > 1"
        if abs(value) > 1:  # Support negative percentages
            return value / 100.0

    return value

# Task 2: Enhanced _dataframe_to_rows column cleaning
def _dataframe_to_rows(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
    # Clean column names (ENHANCED with newline/tab removal)
    cleaned_columns = []
    for col in df.columns:
        col_str = str(col).strip() if col is not None else ""
        # NEW: Remove newlines and tabs from headers
        col_str = col_str.replace("\n", "").replace("\t", "")
        # EXISTING: Handle unnamed columns
        if re.match(r'^Unnamed:\s*\d+', col_str):
            cleaned_columns.append("")
        else:
            cleaned_columns.append(col_str)
    # ... rest of method unchanged

# Task 3: Enhanced _extract_plan_code with ^F stripping
def _extract_plan_code(input_model: AnnuityPerformanceIn, row_index: int) -> Optional[str]:
    # EXISTING: Try Chinese field name first
    if input_model.计划代码:
        plan_code = str(input_model.计划代码).strip()
        # NEW: Strip ^F prefix if present in 组合代码 context
        if hasattr(input_model, '组合代码') and plan_code.startswith('F'):
            plan_code = plan_code[1:]  # Remove leading 'F'
        return plan_code

    logger.debug(f"Row {row_index}: No plan code found")
    return None
```

### Integration Points
```yaml
CLEANSING:
  - file: src/work_data_hub/cleansing/rules/numeric_rules.py
  - functions: handle_percentage_conversion, comprehensive_decimal_cleaning
  - changes: Unicode normalization, negative percentage support

IO_LAYER:
  - file: src/work_data_hub/io/readers/excel_reader.py  
  - method: ExcelReader._dataframe_to_rows
  - changes: Header string normalization for newlines/tabs

DOMAIN_LOGIC:
  - file: src/work_data_hub/domain/annuity_performance/service.py
  - function: _extract_plan_code
  - changes: ^F prefix stripping for 组合代码

TESTS:
  - files: tests/unit/test_cleansing_framework.py, tests/io/test_excel_reader.py, tests/domain/annuity_performance/test_service.py
  - changes: Comprehensive coverage for all new functionality
```

## Validation Loop

### Level 1: Syntax & Style
```bash
# Run these FIRST - fix any errors before proceeding
uv run ruff format .
uv run ruff check src/ --fix
uv run mypy src/

# Expected: No errors. If errors, READ the error and fix.
```

### Level 2: Unit Tests for each enhanced component
```python
# ADD to tests/unit/test_cleansing_framework.py
def test_negative_percentage_conversion():
    """Test negative percentage handling in rate fields."""
    # String negative percentages
    result = comprehensive_decimal_cleaning("-5%", "当期收益率")
    assert result == Decimal("-0.050000")
    
    # Full-width percentage signs  
    result = comprehensive_decimal_cleaning("12.3％", "当期收益率")
    assert result == Decimal("0.123000")
    
    # Numeric negative percentages (abs(value) > 1 rule)
    result = comprehensive_decimal_cleaning(-12.3, "当期收益率") 
    assert result == Decimal("-0.123000")
    
    # Non-rate fields should not convert
    result = comprehensive_decimal_cleaning(5.5, "期初资产规模")
    assert result == Decimal("5.5000")  # Not converted to percentage

# ADD to tests/io/test_excel_reader.py  
def test_header_normalization_removes_newlines_and_tabs(tmp_path):
    """Test Excel header normalization for newlines and tabs."""
    # Create DataFrame with problematic headers
    df_bad_headers = pd.DataFrame({
        "正常列名": ["value1"],
        "包含\n换行符": ["value2"], 
        "包含\t制表符": ["value3"],
        "包含\n\t两者": ["value4"]
    })
    
    file_path = tmp_path / "bad_headers.xlsx"
    df_bad_headers.to_excel(file_path, index=False, engine="openpyxl")
    
    reader = ExcelReader()
    rows = reader.read_rows(str(file_path))
    
    # Verify headers are cleaned
    first_row = rows[0]
    assert "正常列名" in first_row
    assert "包含换行符" in first_row  # \n removed
    assert "包含制表符" in first_row  # \t removed  
    assert "包含两者" in first_row    # Both \n\t removed

# ADD to tests/domain/annuity_performance/test_service.py
def test_extract_plan_code_strips_f_prefix():
    """Test ^F prefix stripping from 组合代码."""
    # Test with F prefix
    input_data = {"计划代码": "FPLAN001", "组合代码": "FPORTFOLIO001"}
    input_model = AnnuityPerformanceIn(**input_data)
    result = _extract_plan_code(input_model, 0)
    assert result == "PLAN001"  # F prefix stripped
    
    # Test without F prefix (should not change)
    input_data = {"计划代码": "PLAN002", "组合代码": "PORTFOLIO002"}
    input_model = AnnuityPerformanceIn(**input_data)
    result = _extract_plan_code(input_model, 0)
    assert result == "PLAN002"  # Unchanged
    
    # Test legitimate F in data (not a prefix)
    input_data = {"计划代码": "FIDELITY001", "组合代码": "FUND001"}
    input_model = AnnuityPerformanceIn(**input_data)
    result = _extract_plan_code(input_model, 0)
    assert result == "IDELITY001"  # Only leading F stripped
```

```bash
# Run targeted tests for each component:
uv run pytest tests/unit/test_cleansing_framework.py -k "percent or percentage" -v
uv run pytest tests/io/test_excel_reader.py -k "header or normalization" -v  
uv run pytest tests/domain/annuity_performance/test_service.py -k "组合代码 or prefix" -v

# Run all tests to ensure no regressions:
uv run pytest -v
```

### Level 3: Integration Test
```bash
# Test the complete pipeline with realistic data
uv run python -c "
from src.work_data_hub.cleansing import comprehensive_decimal_cleaning
from decimal import Decimal

# Test the complete enhancement
test_cases = [
    ('-5%', '当期收益率', Decimal('-0.050000')),
    ('12.3％', '当期收益率', Decimal('0.123000')), 
    (-12.3, '当期收益率', Decimal('-0.123000')),
    (5.5, '期初资产规模', Decimal('5.5000'))
]

for value, field, expected in test_cases:
    result = comprehensive_decimal_cleaning(value, field)
    assert result == expected, f'Failed: {value} -> {result}, expected {expected}'
    
print('✅ All integration tests passed')
"

# Test Excel reading with problematic headers
uv run python -c "
import pandas as pd
from pathlib import Path
from src.work_data_hub.io.readers.excel_reader import ExcelReader

# Create test file with bad headers
df = pd.DataFrame({'Col\nWith\nNewlines': [1], 'Col\tWith\tTabs': [2]})
test_file = Path('/tmp/test_headers.xlsx')
df.to_excel(test_file, index=False)

# Test reading
reader = ExcelReader()
rows = reader.read_rows(str(test_file))
headers = list(rows[0].keys())

assert 'ColWithNewlines' in str(headers), f'Headers not cleaned: {headers}'
print('✅ Header normalization test passed')
"
```

## Final validation Checklist
- [ ] All tests pass: `uv run pytest -v`
- [ ] No linting errors: `uv run ruff check src/ --fix && uv run ruff check src/`
- [ ] No type errors: `uv run mypy src/`
- [ ] Targeted percentage tests: `uv run pytest -k "percent" -v`
- [ ] Targeted header tests: `uv run pytest -k "header" -v`
- [ ] Integration tests successful: Manual validation commands above
- [ ] Backward compatibility: All existing tests still pass
- [ ] API stability: Public cleansing function signatures unchanged

---

## Anti-Patterns to Avoid
- ❌ Don't change public API signatures of comprehensive_decimal_cleaning
- ❌ Don't over-engineer with rule pipeline/DSL - keep KISS principle
- ❌ Don't move company name cleaning into shared component (YAGNI)
- ❌ Don't break existing percentage conversion for valid cases
- ❌ Don't strip legitimate "F" characters that aren't prefixes
- ❌ Don't ignore Unicode edge cases in normalization

## Confidence Score: 9/10
This PRP provides comprehensive context for one-pass implementation including:
- Complete codebase analysis with specific line numbers
- External research captured with actionable implementation notes
- Clear task ordering minimizing integration risk
- Extensive test coverage following existing patterns
- Multiple validation levels with executable commands
- Backward compatibility preservation strategies