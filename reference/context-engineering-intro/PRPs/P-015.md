name: "Local Postgres Test Schema + Smoke E2E (reference/monthly)"
description: |

## Purpose
Enable realistic local testing with Postgres test schema and raw files from `reference/monthly/` to improve production fidelity while keeping CI fast through optional marker-based execution.

## Core Principles
1. **Context is King**: Include ALL necessary documentation, examples, and caveats
2. **Validation Loops**: Provide executable tests/lints the AI can run and fix
3. **Information Dense**: Use keywords and patterns from the codebase
4. **Progressive Success**: Start simple, validate, then enhance
5. **Global rules**: Be sure to follow all rules in CLAUDE.md

---

## Goal
Create a realistic local test harness that runs the existing trustee_performance pipeline against a Postgres test schema and real raw files from `reference/monthly/`. This improves production fidelity while keeping CI fast (optional marker).

## Why
- **Business value**: Enables high-fidelity local testing before production deployment
- **Integration**: Validates complete ETL pipeline with real database and raw data
- **Problems solved**: Bridges gap between unit tests and production deployment; catches integration issues early

## What
A complete local testing infrastructure where:
- Developers can set env overrides and run trustee_performance job plan-only against `reference/monthly/` without code changes
- Local Postgres test schema supports both plan-only and execute modes with real data insertion
- Smoke tests are opt-in via marker and skipped in CI by default
- Clear documentation enables easy local setup and usage

### Success Criteria
- [ ] Developer can run plan-only mode against `reference/monthly/` with env overrides
- [ ] Local Postgres execute mode inserts rows and shows deleted/inserted counts
- [ ] Smoke tests are opt-in via `@pytest.mark.monthly_data` marker
- [ ] README has clear "Local smoke test" setup instructions
- [ ] All validation commands pass locally

## All Needed Context

### Documentation & References
```yaml
# MUST READ - Include these in your context window
- url: https://docs.pytest.org/en/stable/example/markers.html
  why: Custom marker patterns for optional tests
  
- file: tests/io/test_warehouse_loader.py
  why: Existing @pytest.mark.postgres integration test patterns (lines 298-575)
  
- file: tests/e2e/test_trustee_performance_e2e.py  
  why: Complete E2E test patterns with database fixtures (lines 403-575)
  
- file: scripts/create_table/trustee_performance.sql
  why: Existing schema structure to extend for test requirements
  
- file: src/work_data_hub/orchestration/jobs.py
  why: CLI patterns with --plan-only, --execute, --max-files support (lines 131-270)
  
- file: src/work_data_hub/config/settings.py
  why: Environment variable override patterns with WDH_ prefix (lines 58-80)
  
- file: .env.example
  why: Database URI override pattern WDH_DATABASE__URI (lines 65-71)

- file: pyproject.toml
  why: Existing pytest marker configuration pattern (lines 34-37)
```

### Current Codebase tree
```bash
.
├── scripts/
│   └── create_table/
│       ├── trustee_performance.sql     # Existing schema (missing metadata column)
│       └── apply_sql.py
├── tests/
│   ├── io/test_warehouse_loader.py     # @pytest.mark.postgres patterns
│   ├── e2e/test_trustee_performance_e2e.py  # E2E integration patterns
│   └── conftest.py
├── src/work_data_hub/
│   ├── config/settings.py              # WDH_ env var patterns
│   └── orchestration/jobs.py           # CLI with required flags
├── .env.example                        # Database URI override pattern
├── pyproject.toml                      # Existing postgres marker
└── README.md                           # Documentation target
```

### Desired Codebase tree with files to be added
```bash
.
├── scripts/
│   ├── create_table/
│   │   └── (existing files unchanged)
│   └── dev/
│       └── setup_test_schema.sql       # NEW: Test schema DDL
├── tests/
│   ├── smoke/
│   │   └── test_monthly_data_smoke.py  # NEW: Smoke tests with monthly_data marker
│   └── (existing files unchanged)
├── pyproject.toml                      # UPDATED: Add monthly_data marker
└── README.md                           # UPDATED: Add Local Smoke Test section
```

### Known Gotchas & Library Quirks
```python
# CRITICAL: NUMERIC scales must align with Pydantic validators exactly
# From INITIAL.md requirements:
# - return_rate NUMERIC(8,6) 
# - net_asset_value NUMERIC(18,4)
# - fund_scale NUMERIC(18,2)

# CRITICAL: JSONB adaptation - loader already handles dict/list -> psycopg2.extras.Json
# Existing test patterns in test_warehouse_loader.py lines 381-702 show JSONB handling

# CRITICAL: Primary key must match exactly: (report_date, plan_code, company_code)
# From data_sources.yml trustee_performance.primary_key config

# CRITICAL: Test isolation - monthly_data marker must be opt-in, skipped in CI
# Follow patterns from test_warehouse_loader.py @pytest.mark.postgres

# CRITICAL: DDL co-location - schema must be in scripts/dev/setup_test_schema.sql
# Per INITIAL.md: "Keep DDL co-located in scripts/dev/setup_test_schema.sql"

# CRITICAL: Connection timeout - use connect_timeout=5 for fast failure
# Pattern from existing tests: psycopg2.connect(conn_str, connect_timeout=5)
```

## Implementation Blueprint

### Data models and structure

The schema extends the existing trustee_performance table with the metadata JSONB column specified in INITIAL.md:

```sql
-- Based on scripts/create_table/trustee_performance.sql but adds missing metadata column
CREATE TABLE trustee_performance (
    report_date DATE,
    plan_code VARCHAR(50), 
    company_code VARCHAR(20),
    return_rate NUMERIC(8,6),
    net_asset_value NUMERIC(18,4),
    fund_scale NUMERIC(18,2),
    data_source VARCHAR(255),
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    has_performance_data BOOLEAN DEFAULT FALSE,
    validation_warnings JSONB DEFAULT NULL,
    metadata JSONB DEFAULT NULL,  -- NEW: Required by INITIAL.md
    PRIMARY KEY (report_date, plan_code, company_code)
);
```

### List of tasks to be completed to fulfill the PRP in the order they should be completed

```yaml
Task 1: Create Test Schema DDL
CREATE scripts/dev/setup_test_schema.sql:
  - MIRROR pattern from: scripts/create_table/trustee_performance.sql
  - ADD metadata JSONB DEFAULT NULL column per INITIAL.md requirements
  - USE exact column specifications from INITIAL.md lines 30-42
  - KEEP PRIMARY KEY (report_date, plan_code, company_code)

Task 2: Add Monthly Data Pytest Marker  
MODIFY pyproject.toml:
  - FIND pattern: existing markers section (lines 34-37)
  - ADD new marker: monthly_data: marks tests requiring reference/monthly data (opt-in)
  - PRESERVE existing postgres marker pattern

Task 3: Create Smoke Test Module
CREATE tests/smoke/test_monthly_data_smoke.py:
  - MIRROR pattern from: tests/e2e/test_trustee_performance_e2e.py database integration
  - USE @pytest.mark.monthly_data marker  
  - IMPLEMENT discovery validation with WDH_DATA_BASE_DIR=./reference/monthly
  - IMPLEMENT plan-only test with --max-files 2
  - IMPLEMENT optional execute test with database fixture

Task 4: Update README Documentation
MODIFY README.md:
  - FIND pattern: "How to Run" section for insertion point
  - ADD "Local Smoke Test" section with env var setup
  - DOCUMENT plan-only vs execute commands from INITIAL.md
  - DOCUMENT marker activation: pytest -m monthly_data -v
```

### Per task pseudocode

```sql
-- Task 1: Test Schema DDL
-- scripts/dev/setup_test_schema.sql
CREATE TABLE trustee_performance (
    -- PATTERN: Exact specifications from INITIAL.md lines 30-42
    report_date DATE,
    plan_code VARCHAR(50),
    company_code VARCHAR(20), 
    return_rate NUMERIC(8,6),        -- CRITICAL: 6 decimal places
    net_asset_value NUMERIC(18,4),   -- CRITICAL: 4 decimal places  
    fund_scale NUMERIC(18,2),        -- CRITICAL: 2 decimal places
    data_source VARCHAR(255),
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    has_performance_data BOOLEAN DEFAULT FALSE,
    validation_warnings JSONB DEFAULT NULL,
    metadata JSONB DEFAULT NULL,     -- NEW: Required by INITIAL.md
    PRIMARY KEY (report_date, plan_code, company_code)
);
```

```python
# Task 3: Smoke Test Implementation  
# tests/smoke/test_monthly_data_smoke.py

@pytest.mark.monthly_data
class TestMonthlyDataSmoke:
    """Smoke tests using reference/monthly data - opt-in via marker."""
    
    def test_discovery_with_monthly_data(self):
        """Validates discovery when WDH_DATA_BASE_DIR=./reference/monthly."""
        # PATTERN: Use DataSourceConnector like existing E2E tests
        # GOTCHA: Skip if reference/monthly doesn't exist
        
    def test_plan_only_smoke(self):
        """Test plan-only mode with --max-files 2."""
        # PATTERN: Follow jobs.py CLI execution with mocked settings
        # CRITICAL: Use plan_only=True, max_files=2
        
    @pytest.mark.postgres  
    def test_execute_smoke(self, db_connection):
        """Optional execute test with real database."""
        # PATTERN: Follow existing database integration test patterns
        # CRITICAL: Use connect_timeout=5 for fast failure
```

### Integration Points
```yaml
ENVIRONMENT:
  - variables: |
      # Local smoke test overrides
      WDH_DATABASE__URI=postgresql://wdh_user:changeme@localhost:5432/wdh_local
      WDH_DATA_BASE_DIR=./reference/monthly
      
CONFIG:
  - pytest.ini: Add monthly_data marker configuration
  - data_sources.yml: Existing trustee_performance pattern should match reference/monthly
  
CLI:
  - Plan-only: uv run python -m src.work_data_hub.orchestration.jobs --domain trustee_performance --plan-only --max-files 2
  - Execute: uv run python -m src.work_data_hub.orchestration.jobs --domain trustee_performance --execute --max-files 2
  
DATABASE:
  - Schema setup: uv run psql "$WDH_DATABASE__URI" -f scripts/dev/setup_test_schema.sql
  - Connection: Use WDH_DATABASE__URI override with psycopg2 connect_timeout=5
```

## Validation Loop

### Level 1: Syntax & Style
```bash
# Run these FIRST - fix any errors before proceeding
uv run ruff check src/ --fix      # Auto-fix style issues
uv run mypy src/                  # Type checking

# Expected: No errors. If errors, READ and fix.
```

### Level 2: Unit Tests
```bash
# Ensure existing tests still pass
uv run pytest tests/ -v --ignore=tests/smoke/

# Test new smoke module separately (requires setup)
# uv run pytest tests/smoke/ -v  # Only after local setup
```

### Level 3: Integration Test
```bash
# Manual validation following INITIAL.md commands:

# 1. Setup environment
export WDH_DATABASE__URI=postgresql://wdh_user:changeme@localhost:5432/wdh_local  
export WDH_DATA_BASE_DIR=./reference/monthly

# 2. Apply test schema (if database available)
uv run psql "$WDH_DATABASE__URI" -f scripts/dev/setup_test_schema.sql

# 3. Test plan-only mode
uv run python -m src.work_data_hub.orchestration.jobs --domain trustee_performance --plan-only --max-files 2

# Expected: SQL execution plan with DELETE + INSERT operations, no database connection

# 4. Test execute mode (if database available)  
uv run python -m src.work_data_hub.orchestration.jobs --domain trustee_performance --execute --max-files 2

# Expected: Loader summary with deleted/inserted counts

# 5. Test smoke marker
uv run pytest -m monthly_data -v

# Expected: Tests run only when marker is explicitly requested
```

## Final Validation Checklist
- [ ] All existing tests pass: `uv run pytest tests/ -v --ignore=tests/smoke/`
- [ ] No linting errors: `uv run ruff check src/`
- [ ] No type errors: `uv run mypy src/`
- [ ] Plan-only CLI command works with reference/monthly override
- [ ] Execute CLI command works with local database (if available)
- [ ] Smoke tests are skipped by default: `uv run pytest tests/smoke/ -v`
- [ ] Smoke tests run with marker: `uv run pytest -m monthly_data -v`
- [ ] README includes clear local smoke test setup instructions
- [ ] Schema DDL is co-located in scripts/dev/setup_test_schema.sql

---

## Anti-Patterns to Avoid
- ❌ Don't migrate additional domains - scope limited to test infrastructure
- ❌ Don't enable smoke tests in default CI - must be opt-in via marker  
- ❌ Don't alter current unit/E2E test behavior - only add new infrastructure
- ❌ Don't assume psql availability - document GUI client alternatives
- ❌ Don't use different NUMERIC precision than Pydantic validators expect
- ❌ Don't commit reference/monthly data - keep local-only
- ❌ Don't create new file patterns when existing ones work

## Confidence Score: 9/10

High confidence due to:
- Clear requirements from INITIAL.md with specific deliverables
- Existing test patterns to follow in test_warehouse_loader.py and test_trustee_performance_e2e.py  
- Well-established CLI and configuration patterns in jobs.py and settings.py
- Comprehensive validation commands provided in INITIAL.md
- Limited scope focused on test infrastructure, not domain migration

Minor uncertainty on reference/monthly data availability, but tests include appropriate skip conditions.