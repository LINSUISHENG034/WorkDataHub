name: "Company Enrichment Service: Basic Caching & Core Service (KISS/YAGNI)"
description: |

## Purpose
Implement a unified company enrichment service that integrates internal mappings with S-002's EQCClient, completing the company_id resolution and basic caching loop with queue processing for scalable lookups.

## Core Principles
1. **Context is King**: Include ALL necessary documentation, examples, and caveats
2. **Validation Loops**: Provide executable tests/lints the AI can run and fix
3. **Information Dense**: Use keywords and patterns from the codebase
4. **Progressive Success**: Start simple, validate, then enhance
5. **Global rules**: Be sure to follow all rules in CLAUDE.md

---

## Goal
Build a production-ready CompanyEnrichmentService that provides unified company ID resolution with:
- Priority-based internal mapping lookup (highest priority)
- Budget-controlled synchronous EQC lookups with caching
- Asynchronous queue processing for scalable batch operations
- Temporary ID generation for missing customer names
- Robust error handling that doesn't block main processing flow

## Why
- **Business value**: Provides unified, cached company ID resolution across all domains
- **Integration**: Seamlessly integrates existing internal mappings with external EQC data
- **Problems solved**: Eliminates duplicate company resolution logic, provides scalable async processing, enables temporary ID tracking

## What
A service-oriented system where:
- `CompanyEnrichmentService.resolve_company_id()` provides synchronous resolution with configurable EQC budget
- Internal mappings are checked first (using existing resolution logic)
- EQC lookups happen within budget limits, with results cached to `enterprise.company_mapping`
- Failed/over-budget requests queue to `enterprise.lookup_requests` for async processing
- `CompanyEnrichmentService.process_lookup_queue()` consumes queue in batches
- Temporary IDs (`TEMP_000001`) are generated when customer_name is empty

### Success Criteria
- [ ] Service resolves company IDs using priority-based lookup (internal → EQC → queue → temp)
- [ ] EQC results are properly cached to company_mapping table with UPSERT operations
- [ ] Queue processing handles pending requests with proper error handling and retry logic
- [ ] Temporary ID generation is atomic and thread-safe using PostgreSQL sequences
- [ ] All validation gates pass and comprehensive test coverage achieved

## All Needed Context

### Documentation & References
```yaml
# MUST READ - Include these in your context window
- file: src/work_data_hub/domain/company_enrichment/service.py
  why: Existing resolve_company_id function shows priority-based lookup pattern

- file: src/work_data_hub/domain/company_enrichment/models.py
  why: CompanyMappingRecord and CompanyResolutionResult models to extend

- file: src/work_data_hub/io/connectors/eqc_client.py
  why: EQCClient implementation with search_company() and get_company_detail() methods

- file: src/work_data_hub/io/loader/warehouse_loader.py
  why: PostgreSQL operation patterns (atomic operations, error handling)

- file: src/work_data_hub/io/loader/company_mapping_loader.py
  why: Company mapping UPSERT patterns and batch processing

- file: src/work_data_hub/config/settings.py
  why: Configuration patterns using pydantic-settings with WDH_ prefix

- file: tests/domain/company_enrichment/test_models.py
  why: Testing patterns for company enrichment domain

- file: tests/io/test_warehouse_loader.py
  why: Database testing patterns, mock usage, integration tests
</yaml>
```

### Implementation-Facing Research Notes
Purpose: Consolidate external research into actionable, implementation-facing notes to avoid duplicate searching and reduce information drift.

```yaml
sources:
  - type: research
    topic: PostgreSQL queue processing patterns
    why: Atomic dequeue operations for lookup_requests table

  - type: research
    topic: PostgreSQL sequence generation with UPDATE...RETURNING
    why: Thread-safe temporary ID generation

  - type: research
    topic: Service architecture with budget-based sync/async processing
    why: CompanyEnrichmentService design pattern

tldr:
  - PostgreSQL FOR UPDATE SKIP LOCKED enables atomic queue processing without blocking
  - UPDATE...RETURNING pattern provides atomic sequence increment for temp IDs
  - Service constructor injection pattern for dependencies (loader, queue, eqc_client)
  - Budget-based processing: sync up to N requests, queue the rest
  - Error boundaries: catch and log but don't block main processing flow

setup_commands:
  - "# Database setup"
  - "psql $WDH_DATABASE__URI -f scripts/create_table/ddl/lookup_requests.sql"

api_decisions:
  - name: CompanyEnrichmentService.__init__
    choice: "def __init__(self, loader, queue, eqc_client, *, sync_lookup_budget: int = 0)"
    rationale: "Dependency injection pattern, keyword-only budget for clarity"

  - name: resolve_company_id interface
    choice: "resolve_company_id(*, plan_code=None, customer_name=None, account_name=None, sync_lookup_budget=None)"
    rationale: "Matches INITIAL.S-003.md specification exactly, keyword-only args for clarity"

  - name: Queue processing atomic pattern
    choice: "UPDATE jobs SET status='processing' WHERE id=(SELECT id...FOR UPDATE SKIP LOCKED)"
    rationale: "Prevents race conditions in multi-worker scenarios"

versions:
  - library: psycopg2-binary
    constraint: "already in project"
    compatibility: "PostgreSQL operations, connection management"

pitfalls_and_mitigations:
  - issue: "EQC rate limiting or timeouts blocking main flow"
    mitigation: "Catch EQC exceptions, log them, fallback to queueing request"

  - issue: "Queue processing race conditions between multiple workers"
    mitigation: "Use FOR UPDATE SKIP LOCKED pattern for atomic dequeue"

  - issue: "Temporary ID collisions in high-concurrency scenarios"
    mitigation: "Use PostgreSQL UPDATE...RETURNING for atomic sequence increment"

open_questions:
  - "Should failed EQC lookups during sync processing be automatically queued for retry?"
  - "What retry backoff strategy should be used for failed queue processing attempts?"
```

### Current Codebase tree
```bash
src/work_data_hub/
├── config/
│   └── settings.py                    # Pydantic settings with WDH_ prefix
├── domain/
│   └── company_enrichment/
│       ├── models.py                  # CompanyMappingRecord, CompanyResolutionResult
│       └── service.py                 # resolve_company_id function (priority-based)
├── io/
│   ├── connectors/
│   │   └── eqc_client.py             # EQCClient with search/detail methods
│   └── loader/
│       ├── warehouse_loader.py       # PostgreSQL operation patterns
│       └── company_mapping_loader.py # Company mapping UPSERT operations
├── orchestration/
│   └── ops.py                        # Dagster ops for pipeline operations
└── utils/
    └── types.py                      # Shared types and helpers

tests/
├── domain/
│   └── company_enrichment/
│       └── test_models.py            # Company enrichment model tests
├── io/
│   ├── test_warehouse_loader.py      # Database operation testing patterns
│   └── test_company_mapping_loader.py
└── orchestration/
    └── test_ops.py                   # Dagster ops testing patterns
```

### Desired Codebase tree with files to be added
```bash
# NEW FILES
scripts/create_table/ddl/
└── lookup_requests.sql                # DDL for queue table and temp sequence

src/work_data_hub/domain/company_enrichment/
└── lookup_queue.py                   # Queue DAO (enqueue, dequeue, mark_done/failed)

src/work_data_hub/io/loader/
└── company_enrichment_loader.py      # Company mapping UPSERT with caching logic

tests/domain/company_enrichment/
├── test_enrichment_service.py        # CompanyEnrichmentService tests
└── test_lookup_queue.py              # LookupQueue DAO tests

# MODIFIED FILES
src/work_data_hub/domain/company_enrichment/
├── models.py                         # Add ResolutionStatus, CompanyIdResult, LookupRequest
└── service.py                        # Add CompanyEnrichmentService class

src/work_data_hub/config/
└── settings.py                       # Add company enrichment configuration

# OPTIONAL
src/work_data_hub/orchestration/
└── ops.py                           # Add process_lookup_queue_op if needed
```

### Known Gotchas & Library Quirks
```python
# CRITICAL: psycopg2 connection management - always use context managers
# CRITICAL: PostgreSQL FOR UPDATE SKIP LOCKED requires explicit transaction
# CRITICAL: EQC client can raise rate limit errors - must not block main flow
# CRITICAL: Company mapping UPSERT requires careful handling of duplicate keys
# CRITICAL: Temporary ID sequence must be atomic to prevent collisions
# CRITICAL: Queue status transitions must be atomic (pending->processing->done/failed)
# CRITICAL: Use exact field names from INITIAL.S-003.md specification
# CRITICAL: Follow existing normalize_name function for consistency
# CRITICAL: All database operations should support plan_only mode for validation
```

## Implementation Blueprint

### Data models and structure

```python
# models.py - Add these new models to existing file
from enum import Enum
from datetime import datetime, timezone
from typing import Optional

class ResolutionStatus(str, Enum):
    SUCCESS_INTERNAL = "success_internal"      # Found in internal mappings
    SUCCESS_EXTERNAL = "success_external"      # Found via EQC lookup + cached
    PENDING_LOOKUP = "pending_lookup"          # Queued for async lookup
    TEMP_ASSIGNED = "temp_assigned"            # Assigned temporary ID

class CompanyIdResult(BaseModel):
    """Result model for company ID resolution operations."""
    company_id: Optional[str] = Field(None, description="Resolved company_id or temp ID")
    status: ResolutionStatus = Field(..., description="Resolution status")
    source: Optional[str] = Field(None, description="Source of resolution (internal/EQC/temp)")
    temp_id: Optional[str] = Field(None, description="Generated temporary ID if applicable")

class LookupRequest(BaseModel):
    """Model for queued lookup requests."""
    id: Optional[int] = None
    name: str = Field(..., min_length=1, max_length=255)
    normalized_name: str = Field(..., min_length=1, max_length=255)
    status: str = Field(default="pending", description="pending/processing/done/failed")
    attempts: int = Field(default=0, ge=0)
    last_error: Optional[str] = None
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
```

### List of tasks to be completed in order

```yaml
Task 1: Create Database Schema
CREATE scripts/create_table/ddl/lookup_requests.sql:
  - PATTERN: Follow existing DDL patterns from project
  - Create lookup_requests table with status enum
  - Create temp_id_sequence table with atomic increment
  - Add proper indexes for performance (status, normalized_name)

Task 2: Extend Company Enrichment Models
MODIFY src/work_data_hub/domain/company_enrichment/models.py:
  - ADD ResolutionStatus enum with 4 states
  - ADD CompanyIdResult model for service responses
  - ADD LookupRequest model for queue operations
  - PRESERVE existing models and imports

Task 3: Implement Queue DAO
CREATE src/work_data_hub/domain/company_enrichment/lookup_queue.py:
  - PATTERN: Mirror database operation patterns from warehouse_loader.py
  - Implement enqueue(name, normalized_name) -> LookupRequest
  - Implement dequeue(batch_size) -> List[LookupRequest] with atomic FOR UPDATE SKIP LOCKED
  - Implement mark_done(request_id) and mark_failed(request_id, error, attempts++)
  - Support both plan_only and execute modes

Task 4: Create Company Enrichment Loader
CREATE src/work_data_hub/io/loader/company_enrichment_loader.py:
  - PATTERN: Follow company_mapping_loader.py UPSERT patterns
  - Implement cache_company_mapping(alias_name, canonical_id, source="EQC")
  - Support atomic UPSERT operations to enterprise.company_mapping
  - Include proper error handling and logging

Task 5: Implement Temp ID Generation
ADD to Task 3 (lookup_queue.py):
  - FUNCTION: get_next_temp_id() -> str
  - PATTERN: Use UPDATE...RETURNING for atomic sequence increment
  - FORMAT: "TEMP_{number:06d}" (e.g., TEMP_000001)
  - HANDLE: Concurrent access safely with PostgreSQL atomicity

Task 6: Extend Company Enrichment Service
MODIFY src/work_data_hub/domain/company_enrichment/service.py:
  - ADD CompanyEnrichmentService class with dependency injection
  - IMPLEMENT resolve_company_id with exact signature from INITIAL.S-003.md
  - IMPLEMENT process_lookup_queue with batch processing
  - PRESERVE existing resolve_company_id function for backward compatibility
  - INTEGRATE with existing EQCClient, handle all error cases gracefully

Task 7: Add Configuration Settings
MODIFY src/work_data_hub/config/settings.py:
  - ADD company_enrichment_enabled: bool = True
  - ADD company_sync_lookup_limit: int = 5
  - ADD lookup_queue_batch_size: int = 50
  - ADD lookup_retry_max: int = 3
  - ADD lookup_retry_delay: int = 300
  - FOLLOW existing WDH_ environment variable pattern

Task 8: Implement Comprehensive Tests
CREATE tests/domain/company_enrichment/test_enrichment_service.py:
  - TEST internal mapping hits (SUCCESS_INTERNAL)
  - TEST EQC success with caching (SUCCESS_EXTERNAL)
  - TEST budget exhaustion queuing (PENDING_LOOKUP)
  - TEST empty customer_name temp ID (TEMP_ASSIGNED)
  - TEST EQC error handling (graceful fallback to queue)
  - MOCK EQCClient, database operations appropriately

CREATE tests/domain/company_enrichment/test_lookup_queue.py:
  - TEST enqueue/dequeue atomic operations
  - TEST mark_done/mark_failed state transitions
  - TEST concurrent access patterns
  - TEST temp ID generation uniqueness
  - USE database integration test patterns from existing tests

Task 9: Optional Dagster Integration
MODIFY src/work_data_hub/orchestration/ops.py (if requested):
  - ADD process_lookup_queue_op for batch processing
  - FOLLOW existing op patterns with proper configuration
  - INCLUDE context.log for observability
  - HANDLE errors without blocking pipeline
```

### Per task pseudocode

```python
# Task 6: CompanyEnrichmentService Implementation
class CompanyEnrichmentService:
    def __init__(self, loader: CompanyEnrichmentLoader, queue: LookupQueue,
                 eqc_client: EQCClient, *, sync_lookup_budget: int = 0):
        # PATTERN: Dependency injection like existing services
        self.loader = loader
        self.queue = queue
        self.eqc_client = eqc_client
        self.sync_lookup_budget = sync_lookup_budget

    def resolve_company_id(self, *, plan_code=None, customer_name=None,
                          account_name=None, sync_lookup_budget=None) -> CompanyIdResult:
        """
        PRIORITY FLOW (matches INITIAL.S-003.md exactly):
        1. Internal mapping lookup (using existing resolve_company_id function)
        2. If budget > 0: EQC search + detail + cache result
        3. If budget = 0 or EQC fails: queue for async processing
        4. If customer_name empty: generate and return TEMP_* ID
        """

        # Use instance or parameter budget
        budget = sync_lookup_budget if sync_lookup_budget is not None else self.sync_lookup_budget

        # Step 1: Try internal mappings first (highest priority)
        # PATTERN: Use existing resolve_company_id function
        mappings = self.loader.load_mappings()  # Load from database
        query = CompanyMappingQuery(plan_code=plan_code, customer_name=customer_name,
                                  account_name=account_name)
        internal_result = resolve_company_id(mappings, query)

        if internal_result.company_id:
            return CompanyIdResult(
                company_id=internal_result.company_id,
                status=ResolutionStatus.SUCCESS_INTERNAL,
                source=internal_result.match_type
            )

        # Step 2: Try EQC lookup if budget allows
        if budget > 0 and customer_name:
            try:
                # PATTERN: Use existing EQCClient methods
                search_results = self.eqc_client.search_company(customer_name)
                if search_results:
                    # Take first result, get details
                    detail = self.eqc_client.get_company_detail(search_results[0].company_id)

                    # Cache result for future lookups
                    self.loader.cache_company_mapping(
                        alias_name=customer_name,
                        canonical_id=detail.company_id,
                        source="EQC"
                    )

                    return CompanyIdResult(
                        company_id=detail.company_id,
                        status=ResolutionStatus.SUCCESS_EXTERNAL,
                        source="EQC"
                    )
            except Exception as e:
                # CRITICAL: Don't block main flow on EQC errors
                logger.warning(f"EQC lookup failed, will queue: {e}")

        # Step 3: Queue for async processing (if customer_name exists)
        if customer_name:
            normalized = normalize_name(customer_name)  # Use existing function
            self.queue.enqueue(customer_name, normalized)
            return CompanyIdResult(
                company_id=None,
                status=ResolutionStatus.PENDING_LOOKUP,
                source="queued"
            )

        # Step 4: Generate temp ID when customer_name is empty
        temp_id = self.queue.get_next_temp_id()
        return CompanyIdResult(
            company_id=temp_id,
            status=ResolutionStatus.TEMP_ASSIGNED,
            source="generated",
            temp_id=temp_id
        )

    def process_lookup_queue(self, *, batch_size=None) -> int:
        """Process pending lookup requests in batches."""
        batch_size = batch_size or 50  # Default from settings
        processed_count = 0

        # PATTERN: Atomic batch processing
        while True:
            requests = self.queue.dequeue(batch_size)
            if not requests:
                break

            for request in requests:
                try:
                    # Try EQC lookup
                    search_results = self.eqc_client.search_company(request.name)
                    if search_results:
                        detail = self.eqc_client.get_company_detail(search_results[0].company_id)

                        # Cache result
                        self.loader.cache_company_mapping(
                            alias_name=request.name,
                            canonical_id=detail.company_id,
                            source="EQC"
                        )

                        # Mark as done
                        self.queue.mark_done(request.id)
                        processed_count += 1
                    else:
                        # No results found, mark as failed
                        self.queue.mark_failed(request.id, "No EQC results found", request.attempts + 1)

                except Exception as e:
                    # Mark as failed with error details
                    self.queue.mark_failed(request.id, str(e), request.attempts + 1)

        return processed_count
```

### Integration Points
```yaml
DATABASE:
  - migration: "Apply scripts/create_table/ddl/lookup_requests.sql"
  - tables: "enterprise.lookup_requests, enterprise.temp_id_sequence"

CONFIG:
  - add to: src/work_data_hub/config/settings.py
  - env_vars: |
      WDH_COMPANY_ENRICHMENT_ENABLED=true
      WDH_COMPANY_SYNC_LOOKUP_LIMIT=5
      WDH_LOOKUP_QUEUE_BATCH_SIZE=50
      WDH_LOOKUP_RETRY_MAX=3
      WDH_LOOKUP_RETRY_DELAY=300

DEPENDENCIES:
  - existing: EQCClient, CompanyMappingLoader patterns
  - new: LookupQueue, CompanyEnrichmentLoader
  - database: psycopg2 connection management
```

## Validation Loop

### Level 1: Syntax & Style
```bash
# Run these FIRST - fix any errors before proceeding
uv run ruff check src/ --fix
uv run mypy src/
# Expected: No errors. If errors, READ the error and fix.
```

### Level 2: Unit Tests
```python
# test_enrichment_service.py - Key test cases
def test_internal_mapping_hit(mock_mappings, enrichment_service):
    """Test internal mapping lookup returns SUCCESS_INTERNAL"""
    result = enrichment_service.resolve_company_id(plan_code="AN001")
    assert result.status == ResolutionStatus.SUCCESS_INTERNAL
    assert result.company_id == "614810477"
    assert result.source == "plan"

def test_eqc_success_with_caching(mock_eqc_client, enrichment_service):
    """Test EQC lookup with budget returns SUCCESS_EXTERNAL and caches result"""
    result = enrichment_service.resolve_company_id(
        customer_name="中国平安", sync_lookup_budget=1
    )
    assert result.status == ResolutionStatus.SUCCESS_EXTERNAL
    assert result.company_id is not None
    # Verify caching was called
    enrichment_service.loader.cache_company_mapping.assert_called_once()

def test_budget_exhaustion_queues_request(enrichment_service):
    """Test budget=0 queues request for async processing"""
    result = enrichment_service.resolve_company_id(
        customer_name="Test Company", sync_lookup_budget=0
    )
    assert result.status == ResolutionStatus.PENDING_LOOKUP
    # Verify queuing was called
    enrichment_service.queue.enqueue.assert_called_once()

def test_empty_customer_name_generates_temp_id(enrichment_service):
    """Test empty customer_name generates TEMP_* ID"""
    result = enrichment_service.resolve_company_id(plan_code="UNKNOWN")
    assert result.status == ResolutionStatus.TEMP_ASSIGNED
    assert result.temp_id.startswith("TEMP_")
    assert result.company_id == result.temp_id

def test_eqc_error_falls_back_to_queue(mock_eqc_client, enrichment_service):
    """Test EQC errors don't block main flow, fallback to queueing"""
    mock_eqc_client.search_company.side_effect = EQCClientError("Rate limited")

    result = enrichment_service.resolve_company_id(
        customer_name="Test Company", sync_lookup_budget=1
    )
    assert result.status == ResolutionStatus.PENDING_LOOKUP
    # Verify graceful error handling and queueing
    enrichment_service.queue.enqueue.assert_called_once()

# test_lookup_queue.py - Key test cases
def test_enqueue_dequeue_atomic_operations():
    """Test atomic enqueue and dequeue operations"""
    queue = LookupQueue(connection)

    # Enqueue request
    request = queue.enqueue("Test Company", "test company")
    assert request.status == "pending"

    # Dequeue should return the request and mark as processing
    requests = queue.dequeue(batch_size=1)
    assert len(requests) == 1
    assert requests[0].status == "processing"

def test_temp_id_generation_uniqueness():
    """Test temporary ID generation is unique and properly formatted"""
    queue = LookupQueue(connection)

    id1 = queue.get_next_temp_id()
    id2 = queue.get_next_temp_id()

    assert id1 != id2
    assert id1.startswith("TEMP_")
    assert len(id1) == 11  # "TEMP_" + 6 digits
    assert id1.match(r"TEMP_\d{6}")
```

```bash
# Run tests iteratively until passing:
uv run pytest -v -k "enrichment_service or lookup_queue"
# If failing: Read error, understand root cause, fix code, re-run
```

### Level 3: Integration Test
```bash
# Test database setup
export WDH_DATABASE__URI=postgresql://user:pass@host:5432/db
psql "$WDH_DATABASE__URI" -f scripts/create_table/ddl/lookup_requests.sql

# Test service integration
uv run python -c "
from src.work_data_hub.domain.company_enrichment.service import CompanyEnrichmentService
from src.work_data_hub.config.settings import get_settings

settings = get_settings()
service = CompanyEnrichmentService(...)  # Initialize with deps
result = service.resolve_company_id(customer_name='测试公司', sync_lookup_budget=1)
print(f'Result: {result}')
"

# Expected: CompanyIdResult with appropriate status and company_id
```

## Final Validation Checklist
- [ ] All tests pass: `uv run pytest -v -k "enrichment_service or lookup_queue"`
- [ ] No linting errors: `uv run ruff check src/`
- [ ] No type errors: `uv run mypy src/`
- [ ] Database schema applied successfully
- [ ] Service resolves internal mappings (SUCCESS_INTERNAL)
- [ ] Service performs EQC lookups within budget (SUCCESS_EXTERNAL)
- [ ] Service queues requests when budget exhausted (PENDING_LOOKUP)
- [ ] Service generates temp IDs for empty customer names (TEMP_ASSIGNED)
- [ ] Queue processing consumes pending requests successfully
- [ ] Error cases handled gracefully without blocking main flow
- [ ] All configuration settings work with WDH_ environment variables

---

## Anti-Patterns to Avoid
- ❌ Don't let EQC errors block main processing flow - always fallback gracefully
- ❌ Don't use sync database operations in async context (if adding async later)
- ❌ Don't hardcode configuration values - use settings with WDH_ prefix
- ❌ Don't ignore existing normalize_name function - reuse for consistency
- ❌ Don't skip atomic operations for queue processing - use FOR UPDATE SKIP LOCKED
- ❌ Don't forget to cache EQC results - defeats the purpose of the caching mechanism
- ❌ Don't modify existing resolve_company_id function signature - preserve backward compatibility

## Confidence Score: 9/10

High confidence due to:
- Comprehensive analysis of existing codebase patterns and models
- Clear integration points with existing EQCClient and database operations
- Well-researched external patterns for queue processing and service architecture
- Detailed validation gates that cover all major functionality
- Extensive error handling that prevents blocking main processing flow
- Exact adherence to INITIAL.S-003.md interface specification

Minor uncertainty only around optimal retry backoff strategy for queue processing, but this can be refined during implementation based on testing results.