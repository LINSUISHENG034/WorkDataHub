# Story 6.2-P11 éªŒè¯æŒ‡å—

**å˜æ›´ææ¡ˆ**: `docs/sprint-artifacts/sprint-change-proposal/sprint-change-proposal-2025-12-16.md`
**éªŒè¯æ—¥æœŸ**: 2025-12-17
**éªŒè¯ç›®æ ‡**: å‘ç°é¡¹ç›®ä»£ç å­˜åœ¨çš„ä¸è¶³æˆ–ä¼ªå®ç°

---

## éªŒè¯ç›®æ ‡

é€šè¿‡å®é™…è¿è¡Œé¡¹ç›®æ¨¡å—å¹¶æ£€æŸ¥äº§ç”Ÿçš„æ•°æ®ï¼ŒéªŒè¯ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½çš„å®ç°è´¨é‡ï¼š

1. **Pipeline å­—æ®µæ´¾ç”Ÿä¿®å¤** - `å¹´é‡‘è´¦æˆ·å·` ä» `é›†å›¢ä¼ä¸šå®¢æˆ·å·` æ´¾ç”Ÿ
2. **enrichment_index è¡¨æ•°æ®å®Œæ•´æ€§** - Legacy æ˜ å°„æ•°æ®æ˜¯å¦æ­£ç¡®å¯¼å…¥
3. **CLI Token é¢„æ£€æµ‹ + è‡ªåŠ¨åˆ·æ–°** - Token éªŒè¯å’Œè‡ªåŠ¨åˆ·æ–°åŠŸèƒ½

---

## éªŒè¯ä¸€ï¼šPipeline å­—æ®µæ´¾ç”Ÿ (`å¹´é‡‘è´¦æˆ·å·`)

### 1.1 éªŒè¯ç›®çš„
ç¡®è®¤ Step 10 æ­£ç¡®å°† `é›†å›¢ä¼ä¸šå®¢æˆ·å·` çš„å€¼å¤åˆ¶åˆ° `å¹´é‡‘è´¦æˆ·å·` å­—æ®µã€‚

### 1.2 éªŒè¯æ–¹æ³•ï¼šç›´æ¥è°ƒç”¨ Pipeline æ¨¡å—

```powershell
# åˆ›å»ºéªŒè¯è„šæœ¬
PYTHONPATH=src uv run --env-file .wdh_env python -c "
import pandas as pd
from work_data_hub.domain.annuity_performance.pipeline_builder import build_bronze_to_silver_pipeline
from work_data_hub.domain.pipelines.types import PipelineContext
from datetime import datetime, timezone

# æ„é€ æµ‹è¯•æ•°æ® - æ¨¡æ‹Ÿ Bronze å±‚åŸå§‹æ•°æ®
test_data = pd.DataFrame({
    'æœˆåº¦': ['202510', '202510', '202510'],
    'ä¸šåŠ¡ç±»å‹': ['ä¼ä¸šå¹´é‡‘å—æ‰˜', 'ä¼ä¸šå¹´é‡‘æŠ•èµ„', 'èŒä¸šå¹´é‡‘å—æ‰˜'],
    'è®¡åˆ’ç±»å‹': ['é›†åˆè®¡åˆ’', 'å•ä¸€è®¡åˆ’', 'èŒä¸šå¹´é‡‘'],
    'è®¡åˆ’ä»£ç ': ['', '', 'P0001'],
    'å®¢æˆ·åç§°': ['æµ‹è¯•å…¬å¸A', 'æµ‹è¯•å…¬å¸B', 'æµ‹è¯•å…¬å¸C'],
    'é›†å›¢ä¼ä¸šå®¢æˆ·å·': ['C12345678', 'C87654321', None],  # å¸¦Cå‰ç¼€å’Œç©ºå€¼
    'æœºæ„åç§°': ['æ·±åœ³', 'åŒ—äº¬', 'ä¸Šæµ·'],
    'æœŸåˆèµ„äº§è§„æ¨¡': [1000000, 2000000, 3000000],
    'æœŸæœ«èµ„äº§è§„æ¨¡': [1100000, 2100000, 3100000],
})

print('=== åŸå§‹æ•°æ® (Bronze) ===')
print(test_data[['å®¢æˆ·åç§°', 'é›†å›¢ä¼ä¸šå®¢æˆ·å·']].to_string())
print()

# æ„å»º Pipeline (ä¸å¯ç”¨ enrichment)
pipeline = build_bronze_to_silver_pipeline(enrichment_service=None)
context = PipelineContext(
    pipeline_name='annuity_performance.bronze_to_silver',
    execution_id='manual-validation-6.2-p11',
    timestamp=datetime.now(timezone.utc),
    config={},
    domain='annuity_performance',
)

# æ‰§è¡Œ Pipeline
result = pipeline.execute(test_data, context)

print('=== å¤„ç†åæ•°æ® (Silver) ===')
print('å¹´é‡‘è´¦æˆ·å· åˆ—æ˜¯å¦å­˜åœ¨:', 'å¹´é‡‘è´¦æˆ·å·' in result.columns)
print()

if 'å¹´é‡‘è´¦æˆ·å·' in result.columns:
    print('å¹´é‡‘è´¦æˆ·å· å€¼:')
    for idx, row in result.iterrows():
        print(f'  {row.get(\"å®¢æˆ·åç§°\", \"N/A\")}: å¹´é‡‘è´¦æˆ·å·={row[\"å¹´é‡‘è´¦æˆ·å·\"]}')

    # éªŒè¯é€»è¾‘
    print()
    print('=== éªŒè¯ç»“æœ ===')
    # æ£€æŸ¥ Cå‰ç¼€æ˜¯å¦è¢«å»é™¤
    if result.loc[0, 'å¹´é‡‘è´¦æˆ·å·'] == '12345678':
        print('âœ… Cå‰ç¼€æ­£ç¡®å»é™¤: C12345678 -> 12345678')
    else:
        print(f'âŒ Cå‰ç¼€æœªæ­£ç¡®å»é™¤: æœŸæœ› 12345678, å®é™… {result.loc[0, \"å¹´é‡‘è´¦æˆ·å·\"]}')

    # æ£€æŸ¥ç©ºå€¼å¤„ç†
    if pd.isna(result.loc[2, 'å¹´é‡‘è´¦æˆ·å·']) or result.loc[2, 'å¹´é‡‘è´¦æˆ·å·'] is None:
        print('âœ… ç©ºå€¼æ­£ç¡®å¤„ç†: None -> None')
    else:
        print(f'âŒ ç©ºå€¼å¤„ç†å¼‚å¸¸: æœŸæœ› None, å®é™… {result.loc[2, \"å¹´é‡‘è´¦æˆ·å·\"]}')
else:
    print('âŒ å¹´é‡‘è´¦æˆ·å· åˆ—ä¸å­˜åœ¨!')
"
```

### 1.3 é¢„æœŸç»“æœ

| å®¢æˆ·åç§° | åŸå§‹é›†å›¢ä¼ä¸šå®¢æˆ·å· | æœŸæœ›å¹´é‡‘è´¦æˆ·å· |
|---------|------------------|--------------|
| æµ‹è¯•å…¬å¸A | C12345678 | 12345678 |
| æµ‹è¯•å…¬å¸B | C87654321 | 87654321 |
| æµ‹è¯•å…¬å¸C | None | None |

### 1.4 æ½œåœ¨é—®é¢˜æ£€æŸ¥ç‚¹

- [ ] `å¹´é‡‘è´¦æˆ·å·` åˆ—æ˜¯å¦å­˜åœ¨äºè¾“å‡º DataFrame
- [ ] `C` å‰ç¼€æ˜¯å¦è¢«æ­£ç¡®å»é™¤ï¼ˆStep 9æ¸…æ´—åå†å¤åˆ¶ï¼‰
- [ ] ç©ºå€¼/None æ˜¯å¦æ­£ç¡®ä¼ é€’
- [ ] Step 10 æ˜¯å¦åœ¨ Step 13 (DropStep) ä¹‹å‰æ‰§è¡Œ

---

## éªŒè¯äºŒï¼šenrichment_index è¡¨æ•°æ®å®Œæ•´æ€§

### 2.1 éªŒè¯ç›®çš„
ç¡®è®¤ `enterprise.enrichment_index` è¡¨å­˜åœ¨ä¸”åŒ…å« Legacy æ˜ å°„æ•°æ®ã€‚

### 2.2 éªŒè¯æ–¹æ³•ï¼šç›´æ¥æŸ¥è¯¢æ•°æ®åº“

```powershell
# æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨åŠæ•°æ®é‡
PYTHONPATH=src uv run --env-file .wdh_env python -c "
from sqlalchemy import create_engine, text
from work_data_hub.config.settings import get_settings

settings = get_settings()
engine = create_engine(settings.get_database_connection_string())

with engine.connect() as conn:
    # 1. æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    result = conn.execute(text('''
        SELECT EXISTS (
            SELECT FROM information_schema.tables
            WHERE table_schema = 'enterprise'
            AND table_name = 'enrichment_index'
        )
    '''))
    table_exists = result.scalar()
    print(f'enrichment_index è¡¨å­˜åœ¨: {table_exists}')

    if not table_exists:
        print('âŒ è¡¨ä¸å­˜åœ¨ï¼Œéœ€è¦æ‰§è¡Œ alembic è¿ç§»')
        exit(1)

    # 2. æ£€æŸ¥æ•°æ®é‡
    result = conn.execute(text('SELECT COUNT(*) FROM enterprise.enrichment_index'))
    total_count = result.scalar()
    print(f'æ€»è®°å½•æ•°: {total_count}')

    if total_count == 0:
        print('âŒ è¡¨ä¸ºç©ºï¼Œéœ€è¦æ‰§è¡Œæ•°æ®è¿ç§»è„šæœ¬')
        exit(1)

    # 3. æŒ‰ lookup_type åˆ†ç»„ç»Ÿè®¡
    result = conn.execute(text('''
        SELECT lookup_type, COUNT(*) as cnt
        FROM enterprise.enrichment_index
        GROUP BY lookup_type
        ORDER BY cnt DESC
    '''))
    print()
    print('æŒ‰ lookup_type åˆ†å¸ƒ:')
    for row in result:
        print(f'  {row[0]}: {row[1]} æ¡')

    # 4. æŒ‰ source_type åˆ†ç»„ç»Ÿè®¡
    result = conn.execute(text('''
        SELECT source, COUNT(*) as cnt
        FROM enterprise.enrichment_index
        GROUP BY source
        ORDER BY cnt DESC
    '''))
    print()
    print('æŒ‰ source åˆ†å¸ƒ:')
    for row in result:
        print(f'  {row[0]}: {row[1]} æ¡')

    # 5. æŠ½æ ·æ£€æŸ¥æ•°æ®è´¨é‡
    result = conn.execute(text('''
        SELECT lookup_key, company_id, lookup_type, source
        FROM enterprise.enrichment_index
        WHERE company_id IS NOT NULL
        LIMIT 5
    '''))
    print()
    print('æ•°æ®æ ·æœ¬ (å‰5æ¡):')
    for row in result:
        print(f'  {row[0]} -> {row[1]} ({row[2]}/{row[3]})')
"
```

### 2.3 é¢„æœŸç»“æœ

- è¡¨ `enterprise.enrichment_index` å­˜åœ¨
- æ€»è®°å½•æ•° > 0ï¼ˆé¢„æœŸçº¦ 30,000+ æ¡ï¼Œæ¥è‡ª legacy è¿ç§»ï¼‰
- `lookup_type` åŒ…å«: `customer_name`, `plan_code`, `account_number` ç­‰
- `source_type` åŒ…å«: `legacy_migration`, `yaml_override` ç­‰

### 2.4 æ½œåœ¨é—®é¢˜æ£€æŸ¥ç‚¹

- [ ] è¡¨æ˜¯å¦å­˜åœ¨ï¼ˆalembic è¿ç§»æ˜¯å¦æ‰§è¡Œï¼‰
- [ ] æ•°æ®æ˜¯å¦ä¸ºç©ºï¼ˆè¿ç§»è„šæœ¬æ˜¯å¦æ‰§è¡Œï¼‰
- [ ] `company_id` æ˜¯å¦æœ‰æ•ˆï¼ˆéç©ºã€æ ¼å¼æ­£ç¡®ï¼‰
- [ ] æ˜¯å¦å­˜åœ¨é‡å¤çš„ `lookup_key`

---

## éªŒè¯ä¸‰ï¼šCLI Token é¢„æ£€æµ‹ + è‡ªåŠ¨åˆ·æ–°

### 3.1 éªŒè¯ç›®çš„
ç¡®è®¤ CLI å¯åŠ¨æ—¶èƒ½æ­£ç¡®éªŒè¯ Token å¹¶åœ¨å¤±æ•ˆæ—¶è§¦å‘è‡ªåŠ¨åˆ·æ–°ã€‚

### 3.2 éªŒè¯æ–¹æ³• Aï¼šToken éªŒè¯å‡½æ•°ç›´æ¥æµ‹è¯•

```powershell
# æµ‹è¯• validate_eqc_token å‡½æ•°
PYTHONPATH=src uv run --env-file .wdh_env python -c "
from work_data_hub.infrastructure.enrichment.eqc_provider import validate_eqc_token
from work_data_hub.config.settings import get_settings

settings = get_settings()
token = settings.eqc_token
base_url = settings.eqc_base_url

print('=== Token éªŒè¯æµ‹è¯• ===')
print(f'Token é…ç½®: {\"å·²é…ç½®\" if token else \"æœªé…ç½®\"}')
print(f'Base URL: {base_url}')

if token:
    print()
    print('æ­£åœ¨éªŒè¯ Token...')
    is_valid = validate_eqc_token(token, base_url)
    print(f'Token æœ‰æ•ˆ: {is_valid}')

    if is_valid:
        print('âœ… Token éªŒè¯é€šè¿‡')
    else:
        print('âŒ Token å·²å¤±æ•ˆï¼Œéœ€è¦åˆ·æ–°')
else:
    print('âš ï¸ æœªé…ç½® Token (WDH_EQC_TOKEN)')
"
```

### 3.3 éªŒè¯æ–¹æ³• Bï¼šCLI å‚æ•°è§£ææµ‹è¯•

```powershell
# æµ‹è¯• --no-auto-refresh-token å‚æ•°æ˜¯å¦è¢«æ­£ç¡®è§£æ
PYTHONPATH=src uv run --env-file .wdh_env python -c "
import sys
sys.argv = ['etl', '--domains', 'annuity_performance', '--no-auto-refresh-token', '--help']

from work_data_hub.cli.etl import main
import argparse

# æ‰‹åŠ¨è§£æå‚æ•°æ£€æŸ¥
parser = argparse.ArgumentParser()
parser.add_argument('--no-auto-refresh-token', action='store_true', default=False)
parser.add_argument('--domains', type=str)

args, _ = parser.parse_known_args(['--domains', 'annuity_performance', '--no-auto-refresh-token'])
print(f'--no-auto-refresh-token å‚æ•°å€¼: {args.no_auto_refresh_token}')
print(f'âœ… å‚æ•°è§£ææ­£ç¡®' if args.no_auto_refresh_token else 'âŒ å‚æ•°è§£æå¤±è´¥')
"
```

### 3.4 éªŒè¯æ–¹æ³• Cï¼šè‡ªåŠ¨åˆ·æ–°æµç¨‹æµ‹è¯•ï¼ˆéœ€è¦äººå·¥äº¤äº’ï¼‰

```powershell
# æµ‹è¯•è‡ªåŠ¨åˆ·æ–°æµç¨‹ - ä¼šå¼¹å‡ºäºŒç»´ç çª—å£
PYTHONPATH=src uv run --env-file .wdh_env python -c "
from work_data_hub.io.auth.auto_eqc_auth import run_get_token_auto_qr

print('=== è‡ªåŠ¨åˆ·æ–°æµç¨‹æµ‹è¯• ===')
print('å³å°†å¼¹å‡ºäºŒç»´ç çª—å£ï¼Œè¯·ä½¿ç”¨ã€Œå¿«ä¹å¹³å®‰ã€APPæ‰«ç ...')
print('(å¦‚æœä¸æƒ³æµ‹è¯•ï¼Œè¯·åœ¨ 10 ç§’å†…å…³é—­çª—å£)')
print()

token = run_get_token_auto_qr(timeout_seconds=60, save_to_env=False)

if token:
    print(f'âœ… Token è·å–æˆåŠŸ: {token[:8]}...{token[-4:]}')
else:
    print('âŒ Token è·å–å¤±è´¥æˆ–ç”¨æˆ·å–æ¶ˆ')
"
```

### 3.5 éªŒè¯æ–¹æ³• Dï¼šå®Œæ•´ CLI æµç¨‹æµ‹è¯•ï¼ˆDry-runï¼‰

```powershell
# å®Œæ•´ CLI æµç¨‹æµ‹è¯• - ä¸å®é™…æ‰§è¡Œæ•°æ®åº“æ“ä½œ
PYTHONPATH=src uv run --env-file .wdh_env python -m work_data_hub.cli etl --domains annuity_performance --period 202510 --enrichment-enabled
```

è§‚å¯Ÿè¾“å‡ºä¸­æ˜¯å¦åŒ…å«ï¼š
- `ğŸ” Validating EQC token...` - Token éªŒè¯å¼€å§‹
- `âœ… Token valid` æˆ– `âŒ Token invalid/expired` - éªŒè¯ç»“æœ
- å¦‚æœå¤±æ•ˆï¼Œæ˜¯å¦è§¦å‘ `Attempting to refresh token via QR login...`

### 3.6 é¢„æœŸç»“æœ

| åœºæ™¯ | é¢„æœŸè¡Œä¸º |
|-----|---------|
| Token æœ‰æ•ˆ | æ˜¾ç¤º `âœ… Token valid`ï¼Œç»§ç»­æ‰§è¡Œ |
| Token å¤±æ•ˆ + è‡ªåŠ¨åˆ·æ–°å¼€å¯ | å¼¹å‡ºäºŒç»´ç çª—å£ |
| Token å¤±æ•ˆ + `--no-auto-refresh-token` | æ˜¾ç¤ºè­¦å‘Šï¼Œç»§ç»­æ‰§è¡Œï¼ˆæ—  EQC æŸ¥è¯¢ï¼‰ |
| æ—  Token é…ç½® | æ˜¾ç¤º `âš ï¸ No EQC token configured` |

### 3.7 æ½œåœ¨é—®é¢˜æ£€æŸ¥ç‚¹

- [ ] `validate_eqc_token` å‡½æ•°æ˜¯å¦æ­£ç¡®å¤„ç†ç½‘ç»œé”™è¯¯
- [ ] è‡ªåŠ¨åˆ·æ–°æ˜¯å¦æ­£ç¡®ä¿å­˜ Token åˆ° `.wdh_env`
- [ ] `--no-auto-refresh-token` å‚æ•°æ˜¯å¦ç”Ÿæ•ˆ
- [ ] é `annuity_performance` åŸŸæ˜¯å¦è·³è¿‡ Token æ£€æŸ¥

---

## éªŒè¯å››ï¼šç«¯åˆ°ç«¯æ•°æ®æµéªŒè¯

### 4.1 éªŒè¯ç›®çš„
ä½¿ç”¨çœŸå®æ•°æ®éªŒè¯å®Œæ•´ ETL æµç¨‹ï¼Œç¡®è®¤ `å¹´é‡‘è´¦æˆ·å·` å’Œ `company_id` æ­£ç¡®è§£æã€‚

### 4.2 éªŒè¯æ–¹æ³•ï¼šDry-run æ¨¡å¼æ‰§è¡Œ

```powershell
# ä½¿ç”¨ 202510 æœˆåº¦æ•°æ®æ‰§è¡ŒéªŒè¯ï¼ˆå»ºè®®å…ˆ dry-run/plan-only çœ‹æ‰§è¡Œè®¡åˆ’ï¼Œå†ç”¨ --execute å†™å…¥ DBï¼‰
PYTHONPATH=src uv run --env-file .wdh_env python -m work_data_hub.cli etl \
    --domains annuity_performance \
    --period 202510 \
    --enrichment-enabled \
    --debug
```

### 4.3 éªŒè¯æ•°æ®æ£€æŸ¥

æ‰§è¡Œåï¼Œæ£€æŸ¥è¾“å‡ºçš„ DataFrame æˆ–æ•°æ®åº“ä¸­çš„æ•°æ®ï¼š

```powershell
# æ£€æŸ¥å¤„ç†åçš„æ•°æ®
PYTHONPATH=src uv run --env-file .wdh_env python -c "
from sqlalchemy import create_engine, text
from work_data_hub.config.settings import get_settings

settings = get_settings()
engine = create_engine(settings.get_database_connection_string())

with engine.connect() as conn:
    # æ£€æŸ¥ business.è§„æ¨¡æ˜ç»† è¡¨ä¸­ 202510 æ•°æ®
    result = conn.execute(text('''
        SELECT
            COUNT(*) as total,
            COUNT("å¹´é‡‘è´¦æˆ·å·") as with_account_number,
            COUNT(CASE WHEN company_id NOT LIKE 'IN_%' THEN 1 END) as resolved_company_id
        FROM business."è§„æ¨¡æ˜ç»†"
        WHERE æœˆåº¦ = '2025-10-01'
    '''))
    row = result.fetchone()

    if row:
        total, with_account, resolved = row
        print(f'=== 202510 æ•°æ®ç»Ÿè®¡ ===')
        print(f'æ€»è®°å½•æ•°: {total}')
        print(f'æœ‰å¹´é‡‘è´¦æˆ·å·: {with_account} ({with_account/total*100:.1f}%)')
        print(f'å·²è§£æ company_id: {resolved} ({resolved/total*100:.1f}%)')

        # æˆåŠŸæ ‡å‡†
        if with_account / total > 0.5:
            print('âœ… å¹´é‡‘è´¦æˆ·å·å¡«å……ç‡ > 50%')
        else:
            print('âŒ å¹´é‡‘è´¦æˆ·å·å¡«å……ç‡è¿‡ä½')

        if resolved / total > 0.5:
            print('âœ… company_id è§£æç‡ > 50%')
        else:
            print('âŒ company_id è§£æç‡è¿‡ä½ (å¤§é‡ IN_xxx ä¸´æ—¶ID)')
    else:
        print('âš ï¸ æœªæ‰¾åˆ° 202510 æ•°æ®')
"
```

### 4.4 æˆåŠŸæ ‡å‡†ï¼ˆæ¥è‡ªå˜æ›´ææ¡ˆï¼‰

1. âœ… `å¹´é‡‘è´¦æˆ·å·` æ­£ç¡®ä» `é›†å›¢ä¼ä¸šå®¢æˆ·å·` æ´¾ç”Ÿ
2. âœ… `enrichment_index` è¡¨åŒ…å« Legacy æ˜ å°„æ•°æ®
3. âœ… 202510 æœˆåº¦æ•°æ® `company_id` è§£æç‡ > 50% (éä¸´æ—¶ ID)
4. âœ… CLI Token é¢„æ£€æµ‹æ­£å¸¸å·¥ä½œ

---

## éªŒè¯äº”ï¼šè¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸å¤„ç†

### 5.1 ç©ºæ•°æ®å¤„ç†

```powershell
PYTHONPATH=src uv run --env-file .wdh_env python -c "
import pandas as pd
from work_data_hub.domain.annuity_performance.pipeline_builder import build_bronze_to_silver_pipeline
from work_data_hub.domain.pipelines.types import PipelineContext
from datetime import datetime, timezone

# æµ‹è¯•ç©º DataFrame
empty_df = pd.DataFrame(columns=['æœˆåº¦', 'ä¸šåŠ¡ç±»å‹', 'è®¡åˆ’ç±»å‹', 'å®¢æˆ·åç§°', 'é›†å›¢ä¼ä¸šå®¢æˆ·å·'])
pipeline = build_bronze_to_silver_pipeline(enrichment_service=None)
context = PipelineContext(
    pipeline_name='annuity_performance.bronze_to_silver',
    execution_id='manual-validation-empty',
    timestamp=datetime.now(timezone.utc),
    config={},
    domain='annuity_performance',
)

try:
    result = pipeline.execute(empty_df, context)
    print(f'âœ… ç©ºæ•°æ®å¤„ç†æˆåŠŸï¼Œè¾“å‡ºè¡Œæ•°: {len(result)}')
except Exception as e:
    print(f'âŒ ç©ºæ•°æ®å¤„ç†å¤±è´¥: {e}')
"
```

### 5.2 ç¼ºå¤±åˆ—å¤„ç†

```powershell
PYTHONPATH=src uv run --env-file .wdh_env python -c "
import pandas as pd
from work_data_hub.domain.annuity_performance.pipeline_builder import build_bronze_to_silver_pipeline
from work_data_hub.domain.pipelines.types import PipelineContext
from datetime import datetime, timezone

# æµ‹è¯•ç¼ºå°‘ é›†å›¢ä¼ä¸šå®¢æˆ·å· åˆ—
df_no_column = pd.DataFrame({
    'æœˆåº¦': ['202510'],
    'ä¸šåŠ¡ç±»å‹': ['ä¼ä¸šå¹´é‡‘å—æ‰˜'],
    'è®¡åˆ’ç±»å‹': ['é›†åˆè®¡åˆ’'],
    'å®¢æˆ·åç§°': ['æµ‹è¯•å…¬å¸'],
    # æ•…æ„ä¸åŒ…å« é›†å›¢ä¼ä¸šå®¢æˆ·å·
})

pipeline = build_bronze_to_silver_pipeline(enrichment_service=None)
context = PipelineContext(
    pipeline_name='annuity_performance.bronze_to_silver',
    execution_id='manual-validation-missing-column',
    timestamp=datetime.now(timezone.utc),
    config={},
    domain='annuity_performance',
)

try:
    result = pipeline.execute(df_no_column, context)
    if 'å¹´é‡‘è´¦æˆ·å·' in result.columns:
        print(f'å¹´é‡‘è´¦æˆ·å· å€¼: {result[\"å¹´é‡‘è´¦æˆ·å·\"].iloc[0]}')
        if pd.isna(result['å¹´é‡‘è´¦æˆ·å·'].iloc[0]) or result['å¹´é‡‘è´¦æˆ·å·'].iloc[0] is None:
            print('âœ… ç¼ºå¤±åˆ—æ­£ç¡®å¤„ç†ä¸º None')
        else:
            print('âŒ ç¼ºå¤±åˆ—å¤„ç†å¼‚å¸¸')
    else:
        print('âŒ å¹´é‡‘è´¦æˆ·å· åˆ—æœªåˆ›å»º')
except Exception as e:
    print(f'âŒ ç¼ºå¤±åˆ—å¤„ç†å¤±è´¥: {e}')
"
```

---

## æ€»ç»“ï¼šéªŒè¯æ£€æŸ¥æ¸…å•

| éªŒè¯é¡¹ | éªŒè¯æ–¹æ³• | é€šè¿‡æ ‡å‡† |
|-------|---------|---------|
| Pipeline Step 10 å­˜åœ¨ | ä»£ç å®¡æŸ¥ | `pipeline_builder.py:261-267` |
| å¹´é‡‘è´¦æˆ·å· æ­£ç¡®æ´¾ç”Ÿ | éªŒè¯ä¸€ | Cå‰ç¼€å»é™¤ï¼Œå€¼æ­£ç¡®å¤åˆ¶ |
| enrichment_index è¡¨å­˜åœ¨ | éªŒè¯äºŒ | è¡¨å­˜åœ¨ä¸”æœ‰æ•°æ® |
| Legacy æ•°æ®å·²è¿ç§» | éªŒè¯äºŒ | è®°å½•æ•° > 10,000 |
| Token éªŒè¯å‡½æ•°å·¥ä½œ | éªŒè¯ä¸‰A | è¿”å› True/False |
| CLI å‚æ•°è§£ææ­£ç¡® | éªŒè¯ä¸‰B | `--no-auto-refresh-token` ç”Ÿæ•ˆ |
| è‡ªåŠ¨åˆ·æ–°æµç¨‹å·¥ä½œ | éªŒè¯ä¸‰C | äºŒç»´ç çª—å£å¼¹å‡º |
| ç«¯åˆ°ç«¯æ•°æ®æ­£ç¡® | éªŒè¯å›› | è§£æç‡ > 50% |
| è¾¹ç•Œæ¡ä»¶å¤„ç† | éªŒè¯äº” | æ— å¼‚å¸¸æŠ›å‡º |

---

## ä»£ç å‚è€ƒ

| æ–‡ä»¶ | è¡Œå· | è¯´æ˜ |
|-----|------|-----|
| `pipeline_builder.py` | 261-267 | Step 10: å¹´é‡‘è´¦æˆ·å·æ´¾ç”Ÿ |
| `pipeline_builder.py` | 254-259 | Step 9: é›†å›¢ä¼ä¸šå®¢æˆ·å·æ¸…æ´— |
| `etl.py` | 39-104 | Token éªŒè¯å’Œè‡ªåŠ¨åˆ·æ–° |
| `eqc_provider.py` | 104-134 | `validate_eqc_token()` å‡½æ•° |
| `auto_eqc_auth.py` | 507-538 | `run_get_token_auto_qr()` å‡½æ•° |
