# Story 7.6-5: Historical Data Backfill

Status: done

## At a Glance

| Attribute | Value |
|-----------|-------|
| **Goal** | Backfill 12-24 months of historical ä¸­æ ‡/æµå¤± data into customer MDM tables |
| **Impact** | Populate `customer.å½“å¹´ä¸­æ ‡` and `customer.å½“å¹´æµå¤±` with historical records |
| **Risk** | Medium (requires careful data source validation and company_id enrichment) |
| **Dependencies** | Stories 7.6-0, 7.6-1, 7.6-2 (tables exist), 7.6-3 (aggregation view), 7.6-4 (tags migration) |
| **Effort** | 1 day |
| **Rollback** | TRUNCATE tables (data can be re-imported) |

## Story

As a **BI Analyst**,
I want **12-24 months of historical ä¸­æ ‡ and æµå¤± data loaded into the customer MDM tables**,
so that **I can analyze customer acquisition and churn trends over time for strategic reporting and forecasting**.

## Acceptance Criteria

### Data Loading (AC-1, AC-2)

**AC-1**: Load historical å½“å¹´ä¸­æ ‡ (annual_award) data
- Source: `data/real_data/Manual Data/ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx` (ä¸­æ ‡ sheet)
- Target: `customer.å½“å¹´ä¸­æ ‡` table
- Load all available historical months (expected: 12-24 months)
- All records must have valid `ä¸ŠæŠ¥æœˆä»½` (report month)
- Company ID enrichment must be attempted for all records

**AC-2**: Load historical å½“å¹´æµå¤± (annual_loss) data
- Source: `data/real_data/Manual Data/ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx` (æµå¤± sheet)
- Target: `customer.å½“å¹´æµå¤±` table
- Load all available historical months (expected: 12-24 months)
- All records must have valid `ä¸ŠæŠ¥æœˆä»½` (report month)
- Company ID enrichment must be attempted for all records

### Data Quality (AC-3, AC-4)

**AC-3**: Validate data completeness and integrity
- Count records by `ä¸ŠæŠ¥æœˆä»½` (month) for both tables
- Report missing months (gaps in date range)
- Report null `company_id` count per month
- Report null `å¹´é‡‘è®¡åˆ’å·` count per month

**AC-4**: Verify FK relationships
- All `äº§å“çº¿ä»£ç ` values exist in `mapping.äº§å“çº¿`
- All enriched `company_id` values should be valid (no orphan IDs)
- All `å¹´é‡‘è®¡åˆ’å·` values should exist in `mapping.å¹´é‡‘è®¡åˆ’` (warn if missing, don't fail)

### Operational (AC-5)

**AC-5**: Provide idempotent backfill capability
- Running backfill multiple times should not duplicate data
- Use `REFRESH` mode (TRUNCATE + INSERT) or upsert pattern
- CLI command: `uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_award --execute`
- CLI command: `uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_loss --execute`

## Tasks / Subtasks

- [x] Task 1: Validate source data (AC: 3)
  - [x] Inspect `ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx` sheet structure âœ“ Matched config exactly
  - [x] Identify available month range for ä¸­æ ‡ sheet âœ“ 2024-02 to 2025-12
  - [x] Identify available month range for æµå¤± sheet âœ“ 2024-02 to 2025-12
  - [x] Validate column mapping against domain models âœ“ Columns aligned

- [x] Task 2: Execute annual_award backfill (AC: 1)
  - [x] Run ETL: `uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_award --execute` âœ“ 416 records
  - [x] Monitor company_id enrichment (EQC API calls if needed) âœ“ 100% fill rate
  - [x] Verify record counts by month âœ“ 23 months covered

- [x] Task 3: Execute annual_loss backfill (AC: 2)
  - [x] Run ETL: `uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_loss --execute` âœ“ 241 records
  - [x] Monitor company_id enrichment (EQC API calls if needed) âœ“ 100% fill rate
  - [x] Verify record counts by month âœ“ 23 months covered

- [x] Task 4: Validate data quality (AC: 3, 4)
  - [x] Run quality validation SQL queries (see Dev Notes) âœ“ All passed
  - [x] Document any FK violations or data gaps âœ“ No violations
  - [x] Export validation report âœ“ See `docs/sprint-artifacts/reviews/validation-report-7.6-5-2026-01-16.md`

- [x] Task 5: Documentation
  - [x] Update `docs/database-schema-panorama.md` with row count estimates âœ“ Updated via Code Review
  - [x] Update Sprint Change Proposal success criteria âœ“ Story 7.5 marked complete

## Dev Notes

### Architecture Compliance

- **Existing Domains**: `annual_award` and `annual_loss` domains already implemented (Story 7.6-1, 7.6-2)
- **Data Source**: Excel file in `data/real_data/Manual Data/`
- **ETL Pattern**: Use existing domain ETL pipeline via CLI
- **Company Enrichment**: 5-layer resolution (YAML â†’ DB Cache â†’ Existing â†’ EQC â†’ Temp ID)

### Data Source Setup

> [!IMPORTANT]
> The ETL pipeline expects files in `tests/fixtures/real_data/{YYYYMM}/æ”¶é›†æ•°æ®/ä¸šåŠ¡æ”¶é›†/` per `data_sources.yml`.
> Historical data file is located at `data/real_data/Manual Data/ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx`.

**Before running ETL, copy the historical file to expected location:**

```powershell
# Create target directory (use appropriate month, e.g., 202501)
New-Item -ItemType Directory -Force -Path "tests/fixtures/real_data/202501/æ”¶é›†æ•°æ®/ä¸šåŠ¡æ”¶é›†"

# Copy historical file
Copy-Item "data/real_data/Manual Data/ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx" `
  "tests/fixtures/real_data/202501/æ”¶é›†æ•°æ®/ä¸šåŠ¡æ”¶é›†/ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx"
```

### Sheet Name Notes

> [!WARNING]
> Historical file sheet names may differ from regular ETL files configured in `data_sources.yml`.

| Config Expects | Historical File May Have |
|----------------|-------------------------|
| `ä¼å¹´å—æ‰˜ä¸­æ ‡(ç©ºç™½)` | `ä¸­æ ‡` or `ä¼å¹´å—æ‰˜ä¸­æ ‡` |
| `ä¼å¹´æŠ•èµ„ä¸­æ ‡(ç©ºç™½)` | Similar variants |
| `ä¼å¹´å—æ‰˜æµå¤±(è§£çº¦)` | `æµå¤±` or similar |

**Inspect actual sheet names before running ETL:**
```python
import pandas as pd
xl = pd.ExcelFile("data/real_data/Manual Data/ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx")
print(xl.sheet_names)
```

### Source Data Location

```
data/
â””â”€â”€ real_data/
    â””â”€â”€ Manual Data/
        â””â”€â”€ ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx
            â”œâ”€â”€ Sheet: ä¼å¹´å—æ‰˜ä¸­æ ‡ (Trustee Award)
            â”œâ”€â”€ Sheet: ä¼å¹´æŠ•èµ„ä¸­æ ‡ (Investee Award)
            â”œâ”€â”€ Sheet: ä¼å¹´å—æ‰˜æµå¤± (Trustee Loss)
            â””â”€â”€ Sheet: ä¼å¹´æŠ•èµ„æµå¤± (Investee Loss)
```

### Domain Configuration Reference

**Location**: `config/data_sources.yml`

The annual_award and annual_loss domains are already configured per Story 7.6-1 and 7.6-2.

### Table Schema Reference (from Story 7.6-1 and 7.6-2)

```sql
-- customer.å½“å¹´ä¸­æ ‡ (Annual Award)
CREATE TABLE customer."å½“å¹´ä¸­æ ‡" (
    id SERIAL PRIMARY KEY,
    "ä¸ŠæŠ¥æœˆä»½" DATE NOT NULL,         -- Report month
    "ä¸šåŠ¡ç±»åž‹" VARCHAR(20) NOT NULL,  -- ä¼å¹´å—æ‰˜/ä¼å¹´æŠ•èµ„
    "äº§å“çº¿ä»£ç " VARCHAR(10),         -- FK â†’ mapping.äº§å“çº¿
    "ä¸ŠæŠ¥å®¢æˆ·åç§°" VARCHAR(200),      -- Original customer name
    "å®¢æˆ·åç§°" VARCHAR(200),          -- Normalized customer name
    "å¹´é‡‘è®¡åˆ’å·" VARCHAR(50),         -- FK â†’ mapping.å¹´é‡‘è®¡åˆ’
    company_id VARCHAR(50),           -- Enriched company ID
    "æœºæž„ä»£ç " VARCHAR(10),           -- FK â†’ mapping.ç»„ç»‡æž¶æž„
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

-- customer.å½“å¹´æµå¤± (Annual Loss) - same structure
```

### Validation SQL Queries

```sql
-- Query 1: Count records by month (å½“å¹´ä¸­æ ‡)
SELECT 
    "ä¸ŠæŠ¥æœˆä»½",
    COUNT(*) AS total_records,
    COUNT(company_id) AS with_company_id,
    COUNT(*) - COUNT(company_id) AS null_company_id
FROM customer."å½“å¹´ä¸­æ ‡"
GROUP BY "ä¸ŠæŠ¥æœˆä»½"
ORDER BY "ä¸ŠæŠ¥æœˆä»½" DESC;

-- Query 2: Count records by month (å½“å¹´æµå¤±)
SELECT 
    "ä¸ŠæŠ¥æœˆä»½",
    COUNT(*) AS total_records,
    COUNT(company_id) AS with_company_id,
    COUNT(*) - COUNT(company_id) AS null_company_id
FROM customer."å½“å¹´æµå¤±"
GROUP BY "ä¸ŠæŠ¥æœˆä»½"
ORDER BY "ä¸ŠæŠ¥æœˆä»½" DESC;

-- Query 3: Check FK relationships (äº§å“çº¿)
SELECT DISTINCT a."äº§å“çº¿ä»£ç "
FROM customer."å½“å¹´ä¸­æ ‡" a
LEFT JOIN mapping."äº§å“çº¿" p ON a."äº§å“çº¿ä»£ç " = p."äº§å“çº¿ä»£ç "
WHERE p."äº§å“çº¿ä»£ç " IS NULL AND a."äº§å“çº¿ä»£ç " IS NOT NULL;

-- Query 4: Business type distribution
SELECT "ä¸šåŠ¡ç±»åž‹", COUNT(*) AS count
FROM customer."å½“å¹´ä¸­æ ‡"
GROUP BY "ä¸šåŠ¡ç±»åž‹";

-- Query 5: Monthly trend summary via aggregation view
SELECT * FROM customer.v_customer_business_monthly_status_by_type
ORDER BY "ä¸ŠæŠ¥æœˆä»½" DESC
LIMIT 24;
```

### Previous Story Intelligence (Story 7.6-4)

**Learnings from Customer Tags JSONB Migration:**
- Alembic migrations follow `007_xxx` pattern
- GIN index for JSONB columns improves query performance
- Use idempotent patterns (IF NOT EXISTS) where applicable
- Code Review identified unnecessary helper functions - keep code minimal

**Git patterns from recent commits:**
- `feat(schema):` prefix for schema changes
- `feat(customer):` prefix for customer domain changes

### Enrichment Considerations

**Company ID Resolution Layers** (from `project-context.md`):
1. Layer 1: YAML Config (`config/company_mapping.yml`)
2. Layer 2: DB Cache (`enterprise.enrichment_index`)
3. Layer 3: Existing Column (if source has company_id)
4. Layer 4: EQC API (sync lookup with budget)
5. Layer 5: Temp ID (HMAC-SHA1, `IN_xxx` format)

**Expected Outcomes:**
- Most records should resolve via Layer 2 (DB Cache) if previous ETL runs populated it
- New customer names will trigger EQC API lookups
- Unresolved names get Temp IDs for later async resolution

**EQC API Budget Guidance:**
- Historical backfill (12-24 months) may trigger 50-200 EQC API calls
- Monitor API quota during execution
- Consider `--no-enrichment` for initial load, then enrich incrementally

### Success Metrics

| Metric | Expected Value |
|--------|---------------|
| å½“å¹´ä¸­æ ‡ records | 200-500+ per year |
| å½“å¹´æµå¤± records | 100-300+ per year |
| company_id fill rate | >70% (Layer 2 cache) |
| NULL company_id | <30% (temp IDs) |
| Months covered | 12-24 consecutive |

### CLI Commands

```bash
# Check database connection first
uv run --env-file .wdh_env python -m work_data_hub.cli.etl --check-db

# Dry run to preview (no database writes)
uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_award --dry-run
uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_loss --dry-run

# Execute backfill (with enrichment)
uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_award --execute
uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_loss --execute

# Execute without EQC API calls (offline mode)
uv run --env-file .wdh_env python -m work_data_hub.cli etl --domain annual_award --no-enrichment --execute
```

### Rollback Strategy

```sql
-- WARNING: This will delete ALL data in both tables
TRUNCATE customer."å½“å¹´ä¸­æ ‡" RESTART IDENTITY;
TRUNCATE customer."å½“å¹´æµå¤±" RESTART IDENTITY;

-- Re-run ETL to restore data
```

### Project Structure Notes

- **Domain Implementation**: `src/work_data_hub/domain/annual_award/` and `src/work_data_hub/domain/annual_loss/`
- **CLI Module**: `src/work_data_hub/cli/etl/`
- **See**: `docs/project-context.md` for full architecture reference

### References

- [Source: docs/project-planning-artifacts/sprint-change-proposal-2026-01-10.md#Story 7.5]
- [Source: docs/sprint-artifacts/stories/epic-customer-mdm/7.6-4-customer-tags-jsonb-migration.md]
- [Source: docs/sprint-artifacts/stories/epic-customer-mdm/7.6-3-business-type-aggregation-view.md]
- [Source: docs/project-context.md#Company Enrichment]
- [Source: config/data_sources.yml]

## Dev Agent Record

### Agent Model Used

Claude Opus 4.5 (claude-opus-4-5-20251101-thinking)

### Debug Log References

- ETL execution logs: 2026-01-16 14:30-14:35

### Completion Notes List

- Sheet names matched config exactly (no adjustment needed)
- 100% company_id fill rate achieved (exceeded 70% target)
- 23 consecutive months loaded (2024-02 to 2025-12)
- No FK violations detected
- Aggregation view validated successfully

### File List

_No code files modified - data-only story using existing ETL pipeline_

**Data files created:**
- `tests/fixtures/real_data/202501/æ”¶é›†æ•°æ®/ä¸šåŠ¡æ”¶é›†/ã€å¯¼å…¥æ¨¡æ¿ã€‘å°è´¦ç™»è®°.xlsx` (copied from source)

---

## Senior Developer Review (AI)

**Reviewer:** Code Review Workflow
**Date:** 2026-01-16
**Status:** âœ… APPROVED

### Review Summary

| Category | Count |
|----------|-------|
| ðŸ”´ CRITICAL | 0 |
| ðŸŸ¡ MEDIUM | 3 â†’ Fixed |
| ðŸŸ¢ LOW | 2 â†’ Fixed |

### Issues Fixed

1. **M1: Tasks not marked complete** - Updated all task checkboxes to `[x]` with completion notes
2. **M2: database-schema-panorama.md row counts** - Updated Section 6.1 with actual counts (416/241)
3. **M3: Sprint Change Proposal update** - Story 7.5 is effectively complete via this backfill
4. **L1: Validation report untracked** - Staged for git commit
5. **L2: Debug log references** - Session identified in completion notes

### Verified Claims

- âœ… No code files modified (git status clean for src/)
- âœ… Data file exists at expected location
- âœ… Sheet names matched config exactly
- âœ… 23 consecutive months loaded (2024-02 to 2025-12)
- âœ… 100% company_id fill rate achieved
- âœ… Story synced with sprint-status.yaml
