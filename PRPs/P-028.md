name: "Backfill Hardening & Configurability (Skip Facts, Config‑Driven Refs/Schema, Qualified SQL)"
description: |

## Purpose
Harden and parameterize Reference Backfill for production use with configurable targets, schema-qualified SQL generation, and ability to skip fact loading for backfill-only operations.

## Core Principles
1. **Context is King**: Include ALL necessary documentation, examples, and caveats
2. **Validation Loops**: Provide executable tests/lints the AI can run and fix
3. **Information Dense**: Use keywords and patterns from the codebase
4. **Progressive Success**: Start simple, validate, then enhance
5. **Global rules**: Be sure to follow all rules in CLAUDE.md

---

## Goal
Implement a configurable, schema-aware reference backfill system that supports production deployment patterns with proper SQL qualification, skip-facts capability, and configuration-driven table/key definitions.

## Why
- **Production Safety**: Enable backfill-only operations without fact loading risk
- **Configuration Flexibility**: Move hardcoded table/key definitions to declarative YAML configuration
- **Multi-Schema Support**: Support qualified table names for different database schemas
- **Operational Efficiency**: Reduce manual configuration and deployment complexity

## What
A comprehensive enhancement to the reference backfill system providing:
- CLI `--skip-facts` flag for backfill-only execution
- Configuration-driven backfill targets via `data_sources.yml`
- Schema-qualified SQL generation (`"schema"."table"`)
- Backward compatibility with existing deployments
- Enhanced logging and validation

### Success Criteria
- [ ] CLI `--skip-facts` flag works and shows proper status
- [ ] Refs configuration in `data_sources.yml` drives backfill operations
- [ ] Schema-qualified SQL generated when schema is configured
- [ ] All existing tests pass + new focused tests pass
- [ ] README documentation updated with configuration examples
- [ ] Manual validation confirms qualified SQL in logs/plans

## All Needed Context

### Documentation & References
```yaml
# MUST READ - Include these in your context window
- file: INITIAL.md
  why: Complete specification with examples, data contracts, gotchas

- file: src/work_data_hub/orchestration/ops.py
  why: Current backfill_refs_op implementation with hardcoded values

- file: src/work_data_hub/io/loader/warehouse_loader.py
  why: quote_ident function pattern, insert_missing/fill_null_only signatures

- file: src/work_data_hub/orchestration/jobs.py
  why: CLI argument parsing, build_run_config pattern

- file: src/work_data_hub/config/data_sources.yml
  why: Current YAML structure, where to add refs configuration

- file: tests/io/test_warehouse_loader_backfill.py
  why: Existing test patterns for backfill operations

- file: tests/orchestration/test_jobs_run_config.py
  why: CLI configuration test patterns
```

### Implementation-Facing Research Notes
```yaml
sources:
  - external_research: PostgreSQL identifier quoting best practices
    section: schema-qualified names, Unicode handling
    why: Secure SQL generation for "schema"."table" patterns
    type: gemini_research

tldr:
  - PostgreSQL identifiers use double quotes, not single quotes
  - Schema qualification: "schema"."table" - quote each part separately
  - Never use string formatting for identifiers - SQL injection risk
  - Current quote_ident function is secure, need quote_qualified extension
  - Handle None/empty schema gracefully - return just table name

setup_commands:
  - No additional packages required - using existing psycopg2 patterns

api_decisions:
  - name: quote_qualified function signature
    choice: quote_qualified(schema: Optional[str], table: str) -> str
    rationale: Matches existing quote_ident pattern, handles None schema gracefully

  - name: schema parameter placement
    choice: Add optional schema parameter to insert_missing/fill_null_only
    rationale: Backward compatible, follows existing parameter patterns

versions:
  - library: psycopg2
    constraint: existing version
    compatibility: Current quote_ident function works correctly

pitfalls_and_mitigations:
  - issue: SQL injection via identifier concatenation
    mitigation: Use quote_ident for each part, never f-strings or concatenation
  - issue: Breaking backward compatibility
    mitigation: Default to hardcoded values when refs config missing
  - issue: Schema None/empty edge cases
    mitigation: Explicit None checks, return table-only when schema missing

open_questions:
  - Should refs be required or optional in data_sources.yml? (Answer: optional with fallback)
```

### Current Codebase tree
```bash
src/work_data_hub/
  orchestration/
    jobs.py          # CLI parsing, build_run_config, main()
    ops.py           # backfill_refs_op with hardcoded table names
  io/loader/warehouse_loader.py  # quote_ident, insert_missing, fill_null_only
  config/data_sources.yml        # domains config, needs refs block

tests/
  orchestration/test_jobs_run_config.py       # CLI config tests
  orchestration/test_backfill_ops.py          # backfill operation tests
  io/test_warehouse_loader_backfill.py        # loader backfill tests
```

### Desired Codebase tree with files to be modified
```bash
src/work_data_hub/
  orchestration/
    jobs.py          # ADD --skip-facts CLI arg, pass through run_config
    ops.py           # READ refs from data_sources.yml, pass schema/table/key
  io/loader/warehouse_loader.py  # ADD quote_qualified function, schema params
  config/data_sources.yml        # ADD refs block under annuity_performance

tests/
  orchestration/test_jobs_run_config.py       # ADD --skip-facts test case
  orchestration/test_backfill_ops.py          # ADD refs config consumption test
  io/test_warehouse_loader_backfill.py        # ADD quote_qualified tests

README.md           # ADD refs configuration docs, skip-facts usage
VALIDATION.md       # ADD manual validation examples
```

### Known Gotchas of our codebase & Library Quirks
```python
# CRITICAL: Don't pass "schema.table" to quote_ident directly
# WRONG: quote_ident("public.年金计划")
# RIGHT: quote_qualified("public", "年金计划")

# CRITICAL: Preserve ON CONFLICT fallback behavior in insert_missing
# The function handles missing unique constraints gracefully - keep this

# CRITICAL: Handle Chinese characters in table/column names correctly
# Current quote_ident already handles Unicode properly - extend pattern

# CRITICAL: Backward compatibility for missing refs configuration
# Default to existing hardcoded values: 年金计划, 组合计划, public schema

# CRITICAL: Skip facts implementation - use short-circuit in load_op
# Don't remove from DAG, just early-return with logging when skip=True
```

## Implementation Blueprint

### Data models and structure

The refs configuration schema to add to data_sources.yml:
```yaml
# Under domains.annuity_performance:
refs:
  plans:
    schema: public                    # Optional - defaults to current schema
    table: "年金计划"                  # Required
    key: ["年金计划号"]               # Required - list of key columns
    updatable: ["计划全称", "计划类型", "客户名称", "company_id"]  # Required for fill_null_only
  portfolios:
    schema: public                    # Optional
    table: "组合计划"                  # Required
    key: ["组合代码"]                 # Required
    updatable: ["组合名称", "组合类型", "运作开始日"]  # Required for fill_null_only
```

### List of tasks to be completed to fulfill the PRP in the order they should be completed

```yaml
Task 1: Add quote_qualified function to warehouse_loader.py
MODIFY src/work_data_hub/io/loader/warehouse_loader.py:
  - ADD quote_qualified function after quote_ident function
  - PATTERN: Similar to quote_ident but handles schema.table composition
  - VALIDATE: None/empty schema returns table-only, non-empty returns "schema"."table"

Task 2: Update loader functions for schema support
MODIFY src/work_data_hub/io/loader/warehouse_loader.py:
  - MODIFY insert_missing function signature: add schema: Optional[str] = None parameter
  - MODIFY fill_null_only function signature: add schema: Optional[str] = None parameter
  - REPLACE quote_ident(table) with quote_qualified(schema, table) in both functions
  - PRESERVE all existing behavior and error handling

Task 3: Add refs configuration to data_sources.yml
MODIFY src/work_data_hub/config/data_sources.yml:
  - ADD refs block under domains.annuity_performance
  - INCLUDE plans and portfolios with schema, table, key, updatable fields
  - FOLLOW example structure from INITIAL.md

Task 4: Update backfill_refs_op to consume configuration
MODIFY src/work_data_hub/orchestration/ops.py:
  - READ data_sources.yml to extract refs configuration for domain
  - REPLACE hardcoded table names with config-driven values
  - PASS schema parameter to insert_missing/fill_null_only calls
  - ADD fallback to hardcoded values when refs config missing
  - UPDATE logging to show qualified table names

Task 5: Add --skip-facts CLI flag
MODIFY src/work_data_hub/orchestration/jobs.py:
  - ADD --skip-facts argument to parser
  - UPDATE build_run_config to pass skip flag to load_op config
  - UPDATE main() to display skip facts status in summary
  - MODIFY load_op to early-return when skip=True

Task 6: Add comprehensive tests
MODIFY tests/io/test_warehouse_loader_backfill.py:
  - ADD test_quote_qualified_with_schema and test_quote_qualified_without_schema
  - ADD test cases for schema parameter in insert_missing/fill_null_only
  - VERIFY generated SQL contains qualified names

MODIFY tests/orchestration/test_backfill_ops.py:
  - ADD test for refs configuration consumption
  - VERIFY ops pass schema/table/key/updatable correctly

MODIFY tests/orchestration/test_jobs_run_config.py:
  - ADD test for --skip-facts flag mapping to run_config

Task 7: Update documentation
MODIFY README.md:
  - ADD refs configuration examples with schema/table/key/updatable
  - ADD skip-facts CLI usage examples
  - DOCUMENT recommended validation steps

MODIFY VALIDATION.md:
  - ADD manual check examples for qualified SQL
  - DOCUMENT evidence to look for in logs
```

### Per task pseudocode

```python
# Task 1: quote_qualified function
def quote_qualified(schema: Optional[str], table: str) -> str:
    """
    Quote PostgreSQL identifier with optional schema qualification.

    Args:
        schema: Optional schema name
        table: Table name (required)

    Returns:
        Qualified identifier: "schema"."table" or "table"

    Raises:
        ValueError: If table is empty or invalid
    """
    # Validate required table name (reuse quote_ident validation logic)
    if not table or not isinstance(table, str):
        raise ValueError("Table name must be non-empty string")

    # Handle schema qualification
    if schema and str(schema).strip():
        # Both schema and table need individual quoting
        return f"{quote_ident(str(schema))}.{quote_ident(table)}"
    else:
        # Schema is None/empty - return table only
        return quote_ident(table)

# Task 4: Configuration reading in backfill_refs_op
@op
def backfill_refs_op(context, config, plan_candidates, portfolio_candidates):
    # Read refs configuration from data_sources.yml
    settings = get_settings()
    refs_config = {}
    try:
        with open(settings.data_sources_config, "r", encoding="utf-8") as f:
            data_sources = yaml.safe_load(f)

        # Extract refs for current domain (from discover_files_op config)
        domain = "annuity_performance"  # or get from context
        refs_config = data_sources.get("domains", {}).get(domain, {}).get("refs", {})
    except Exception as e:
        context.log.warning(f"Could not load refs config: {e}, using defaults")

    # Get plans configuration with fallbacks
    plans_config = refs_config.get("plans", {})
    plans_schema = plans_config.get("schema")  # None if not specified
    plans_table = plans_config.get("table", "年金计划")  # fallback to hardcoded
    plans_key = plans_config.get("key", ["年金计划号"])  # fallback
    plans_updatable = plans_config.get("updatable", ["计划全称", "计划类型", "客户名称", "company_id"])

    # Execute backfill with config-driven values
    if ("plans" in config.targets or "all" in config.targets) and plan_candidates:
        if config.mode == "insert_missing":
            plan_result = insert_missing(
                table=plans_table,
                key_cols=plans_key,
                rows=plan_candidates,
                conn=conn,
                chunk_size=config.chunk_size,
                schema=plans_schema,  # NEW: pass schema
            )
        # ... similar for portfolios

# Task 5: Skip facts implementation
@op
def load_op(context: OpExecutionContext, config: LoadConfig, processed_rows):
    # NEW: Check skip flag and early return
    if getattr(config, "skip", False):
        context.log.info("Fact loading skipped due to --skip-facts flag")
        return {
            "table": config.table,
            "mode": config.mode,
            "skipped": True,
            "inserted": 0,
            "deleted": 0,
            "batches": 0,
        }

    # Existing load logic continues...
    return load(...)
```

### Integration Points
```yaml
CLI_ARGUMENTS:
  - add to: src/work_data_hub/orchestration/jobs.py parser
  - flag: "--skip-facts" (action="store_true", help="Skip fact loading, run backfill only")

CONFIG_FILES:
  - add to: src/work_data_hub/config/data_sources.yml
  - structure: domains.annuity_performance.refs.{plans,portfolios}
  - fields: schema (optional), table, key (list), updatable (list)

DATABASE_LAYER:
  - modify: insert_missing, fill_null_only function signatures
  - add: optional schema parameter
  - use: quote_qualified instead of quote_ident for table references

ORCHESTRATION:
  - modify: load_op config schema to include skip flag
  - modify: backfill_refs_op to read refs from data_sources.yml
  - log: qualified table names in backfill summaries
```

## Validation Loop

### Level 1: Syntax & Style
```bash
# Run these FIRST - fix any errors before proceeding
uv run ruff check src/ --fix                    # Auto-fix style issues
uv run mypy src/                                 # Type checking

# Expected: No errors. If errors, READ the error and fix.
```

### Level 2: Unit Tests
```python
# tests/io/test_warehouse_loader_backfill.py - Add these test cases:
def test_quote_qualified_with_schema():
    """Test quote_qualified with schema produces qualified name."""
    result = quote_qualified("public", "年金计划")
    assert result == '"public"."年金计划"'

def test_quote_qualified_without_schema():
    """Test quote_qualified with None schema produces table only."""
    result = quote_qualified(None, "年金计划")
    assert result == '"年金计划"'

    result = quote_qualified("", "年金计划")
    assert result == '"年金计划"'

def test_insert_missing_with_schema():
    """Test insert_missing generates qualified SQL when schema provided."""
    result = insert_missing(
        table="年金计划",
        schema="public",
        key_cols=["年金计划号"],
        rows=[{"年金计划号": "PLAN001"}],
        conn=None,
    )

    sql = result["sql_plans"][0][1]
    assert '"public"."年金计划"' in sql

# tests/orchestration/test_jobs_run_config.py - Add this test case:
def test_build_run_config_skip_facts_flag():
    args = SimpleNamespace(
        domain="annuity_performance",
        mode="delete_insert",
        plan_only=True,
        execute=False,
        skip_facts=True,  # NEW
        sheet=0,
        max_files=1,
    )

    run_config = build_run_config(args)

    # Verify skip flag passed to load_op
    load_cfg = run_config["ops"]["load_op"]["config"]
    assert load_cfg["skip"] is True
```

```bash
# Run focused tests iteratively until passing:
uv run pytest -v -k "backfill or run_config or qualified"

# If failing: Debug specific test, fix code, re-run
```

### Level 3: Integration Test
```bash
# Test CLI with skip-facts flag
WDH_DATA_BASE_DIR="tests/fixtures/sample_data/annuity_subsets" uv run python -m src.work_data_hub.orchestration.jobs \
  --domain annuity_performance \
  --plan-only \
  --backfill-refs all \
  --backfill-mode insert_missing \
  --skip-facts \
  --sheet "规模明细" \
  --debug

# Expected output should show:
# Skip facts: True
# Reference Backfill Summary (with qualified table names if schema configured)
# NO fact loading summary

# Test with schema configuration and plan-only
WDH_DATA_BASE_DIR="tests/fixtures/sample_data/annuity_subsets" uv run python -m src.work_data_hub.orchestration.jobs \
  --domain annuity_performance \
  --plan-only \
  --backfill-refs all \
  --backfill-mode insert_missing \
  --sheet "规模明细" \
  --debug

# Expected: SQL plans should contain "public"."年金计划" if schema configured
```

## Final Validation Checklist
- [ ] All tests pass: `uv run pytest tests/ -v`
- [ ] No linting errors: `uv run ruff check src/`
- [ ] No type errors: `uv run mypy src/`
- [ ] Focused tests pass: `uv run pytest -v -k "backfill or run_config or qualified"`
- [ ] CLI shows `Skip facts: True` when --skip-facts used
- [ ] Reference Backfill Summary shows qualified table names when schema configured
- [ ] Both ON CONFLICT fast path and fallback path work correctly
- [ ] Backward compatibility maintained when refs config missing
- [ ] README.md updated with configuration examples
- [ ] VALIDATION.md updated with manual check procedures

---

## Anti-Patterns to Avoid
- ❌ Don't use string formatting for SQL identifiers - quote_qualified handles this safely
- ❌ Don't pass "schema.table" to quote_ident directly - build qualified names properly
- ❌ Don't break backward compatibility - preserve fallback to hardcoded values
- ❌ Don't forget to update BOTH insert_missing AND fill_null_only functions
- ❌ Don't skip validation of refs configuration structure
- ❌ Don't hardcode qualified names in logs when they should be dynamic
- ❌ Don't remove load_op from DAG - use skip flag for early return instead

## Confidence Score: 9/10

High confidence due to:
- Clear specification with examples in INITIAL.md
- Existing patterns in codebase provide solid foundation (quote_ident, test patterns)
- External research provides actionable PostgreSQL identifier quoting best practices
- Comprehensive test coverage already exists for similar functionality
- Clear validation gates with executable commands
- Well-understood backward compatibility requirements

Minor uncertainty only around edge cases in refs configuration parsing, but fallback patterns mitigate this risk.