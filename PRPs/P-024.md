name: "Cleansing Framework Hardening: Alias Serialization, Auto-Identity PKs, and F-Prefix Refinement"
description: |

## Purpose
Complete P-023 validation loop with minimal, KISS-aligned changes to align the annuity domain with the new architecture. This PRP addresses alias-based serialization for JSON handoff, database auto-increment primary keys, and refined F-prefix handling for production-ready data processing.

## Core Principles
1. **Context is King**: Include ALL necessary documentation, examples, and caveats
2. **Validation Loops**: Provide executable tests/lints the AI can run and fix
3. **Information Dense**: Use keywords and patterns from the codebase
4. **Progressive Success**: Start simple, validate, then enhance
5. **Global rules**: Be sure to follow all rules in CLAUDE.md

---

## Goal
Finalize the cleansing framework implementation by enabling proper JSON serialization with database column mapping, implementing modern PostgreSQL auto-identity primary keys, and refining F-prefix stripping logic to be precise and domain-appropriate.

## Why
- **Business value**: Enables production-ready annuity performance data processing with reliable column mapping
- **Integration**: Completes the ETL pipeline architecture with proper JSON handoff between orchestration and loader
- **Problems solved**: Resolves column mismatch errors, eliminates manual ID management, and prevents over-aggressive F-prefix stripping

## What
Complete the P-023 validation loop with these specific changes:
- Enable alias-based, null-excluding serialization in Dagster ops for clean JSON handoff
- Adopt DB auto-increment primary keys using PostgreSQL GENERATED ALWAYS AS IDENTITY
- Narrow F-prefix stripping to only portfolio code (组合代码) with strict pattern matching
- Update tests to use company_id and remove obsolete field assertions

### Success Criteria
- [ ] Ops use `by_alias=True, exclude_none=True` serialization
- [ ] E2E plan shows correct aliased column names (e.g., `"流失(含待遇支付)"`) in INSERT SQL
- [ ] DB auto-generates IDs; execute mode succeeds without providing ID values
- [ ] F-prefix only strips from portfolio code when matching `^F[0-9A-Z]+$`
- [ ] All tests pass with updated company_id assertions and no obsolete fields

## All Needed Context

### Documentation & References
```yaml
# MUST READ - Include these in your context window
- file: INITIAL_en.md
  why: Complete specification of P-023 requirements and acceptance criteria
  
- file: src/work_data_hub/orchestration/ops.py
  why: Current serialization patterns need updating (3 locations)
  lines: [44, 237, 276] # model_dump calls to modify
  
- file: src/work_data_hub/domain/annuity_performance/service.py
  why: F-prefix stripping logic in _extract_plan_code function
  lines: [386-387] # Current problematic logic
  
- file: src/work_data_hub/domain/annuity_performance/models.py
  why: Alias definitions for column mapping (e.g., 流失_含待遇支付 → 流失(含待遇支付))
  
- file: scripts/dev/annuity_performance_real.sql
  why: DDL requiring auto-identity conversion for id column
  lines: [13] # "id" INTEGER NOT NULL to change
  
- file: src/work_data_hub/config/data_sources.yml
  why: Primary key configuration ["月度", "计划代码", "company_id"]
  
- file: tests/domain/annuity_performance/
  why: Test patterns requiring company_id updates and field removals

- doc: CLAUDE.md
  section: Database naming/quoting conventions
  critical: Proper handling of Chinese column identifiers
```

### Implementation-Facing Research Notes
```yaml
sources:
  - type: research
    topic: Pydantic model serialization best practices
    why: Validates the by_alias=True, exclude_none=True approach
    
  - type: research  
    topic: PostgreSQL auto-increment primary keys (14+)
    why: Confirms GENERATED ALWAYS AS IDENTITY is modern best practice

tldr:
  - model_dump(mode="json", by_alias=True, exclude_none=True) is the correct pattern for clean data transfer
  - GENERATED ALWAYS AS IDENTITY with BIGINT is PostgreSQL 14+ best practice for data warehousing
  - Chinese column identifiers require proper quoting in PostgreSQL DDL
  - F-prefix stripping should be surgical, not broad-brush

api_decisions:
  - name: model_dump serialization
    choice: mode="json", by_alias=True, exclude_none=True
    rationale: Ensures proper column mapping and clean JSON without nulls
    
  - name: primary_key_strategy
    choice: GENERATED ALWAYS AS IDENTITY
    rationale: Modern PostgreSQL standard, prevents manual ID conflicts

versions:
  - library: pydantic
    constraint: "v2"
    compatibility: Already in use, aliases working correctly
    
  - database: postgresql
    constraint: ">=12"
    compatibility: GENERATED ALWAYS AS IDENTITY supported

pitfalls_and_mitigations:
  - issue: by_alias=True may unexpectedly affect trustee domain
    mitigation: Trustee models don't use aliases for DB columns, so no-op
    
  - issue: F-prefix logic currently too broad, affects plan code
    mitigation: Add strict pattern matching and field targeting
    
  - issue: Auto-identity requires DDL application before execute
    mitigation: Document DDL dependency and provide clear validation steps

open_questions:
  - None - requirements are precisely specified in INITIAL_en.md
```

### Current Codebase Context
```bash
src/work_data_hub/
├── orchestration/
│   └── ops.py                    # 3 model_dump() calls need by_alias=True, exclude_none=True
├── domain/
│   └── annuity_performance/
│       ├── models.py             # Contains alias mappings (流失_含待遇支付 → 流失(含待遇支付))
│       └── service.py            # F-prefix logic in _extract_plan_code needs narrowing
├── config/
│   └── data_sources.yml          # PK definition: ["月度", "计划代码", "company_id"]
scripts/dev/
└── annuity_performance_real.sql  # DDL needs auto-identity for "id" column
tests/
├── domain/annuity_performance/   # Need company_id updates, remove obsolete assertions
└── legacy/                       # E2E tests for validation
```

### Known Gotchas & Library Quirks
```python
# CRITICAL: Chinese column names require proper quoting in PostgreSQL
# Example: "流失(含待遇支付)" must stay quoted throughout DDL

# CRITICAL: model_dump locations in ops.py (exactly 3 places):
# - Line ~44: process_trustee_performance_op
# - Line ~237: process_annuity_performance_op  
# - Line ~276: read_and_process_trustee_files_op

# CRITICAL: F-prefix pattern must be exact: ^F[0-9A-Z]+$
# Don't strip from words like "FIDELITY001" - only pure F-codes like "F123ABC"

# CRITICAL: Current F-prefix logic incorrectly checks 组合代码 existence but strips from 计划代码
# Need to target the correct field: strip FROM 组合代码, not 计划代码

# CRITICAL: GENERATED ALWAYS AS IDENTITY prevents INSERT with explicit ID
# Any existing synthetic ID generation in code must be removed
```

## Implementation Blueprint

### Data Models and Structure
The alias chain works as follows:
```python
# Input: Excel with header "流失（含待遇支付）" (full-width parentheses)
# ↓ ExcelReader + column_normalizer
# Standardized: "流失_含待遇支付" (underscore, normalized)
# ↓ Pydantic validation
# Model field: 流失_含待遇支付 = Field(alias="流失(含待遇支付)")
# ↓ model_dump(by_alias=True)
# JSON output: {"流失(含待遇支付)": value}
# ↓ Database
# Column: "流失(含待遇支付)" (half-width parentheses, quoted)
```

### List of Tasks (Complete in Order)

```yaml
Task 1: Update Orchestration Serialization
MODIFY src/work_data_hub/orchestration/ops.py:
  - FIND pattern: model_dump(mode="json")
  - REPLACE with: model_dump(mode="json", by_alias=True, exclude_none=True)
  - LOCATIONS: 3 exact occurrences in process ops
  - PRESERVE: All existing logic, only modify serialization calls

Task 2: Implement Auto-Identity Primary Key
MODIFY scripts/dev/annuity_performance_real.sql:
  - FIND pattern: "id" INTEGER NOT NULL
  - REPLACE with: "id" INTEGER GENERATED ALWAYS AS IDENTITY
  - PRESERVE: Primary key constraint and all other DDL structure
  - MAINTAIN: Proper Chinese column quoting throughout

Task 3: Refine F-Prefix Stripping Logic  
MODIFY src/work_data_hub/domain/annuity_performance/service.py:
  - FIND function: _extract_plan_code
  - CURRENT LOGIC: Strips F-prefix when 组合代码 exists and plan_code.startswith("F")
  - NEW LOGIC: Only strip F-prefix from 组合代码 field itself, only when matching ^F[0-9A-Z]+$
  - PRESERVE: All other plan code extraction logic
  - CREATE helper function for strict pattern matching

Task 4: Update Test Assertions
MODIFY tests/domain/annuity_performance/ files:
  - UPDATE: Replace any company_code assertions with company_id
  - REMOVE: Assertions for data_source, processed_at, validation_warnings fields
  - ADD: Assertions verifying alias serialization produces correct JSON keys
  - PRESERVE: All other test logic and validation patterns

Task 5: Validate Column Alignment
VERIFY: E2E plan mode shows correct column names in generated SQL
  - JSON serialization produces: "流失(含待遇支付)" 
  - DDL column matches: "流失(含待遇支付)"
  - Primary key fields align with data_sources.yml configuration
```

### Per Task Pseudocode

```python
# Task 1: Orchestration Updates
# In ops.py, update serialization calls:
def process_annuity_performance_op(...):
    # ... existing logic ...
    
    # OLD: 
    result_dicts = [model.model_dump(mode="json") for model in processed_models]
    
    # NEW:
    result_dicts = [model.model_dump(mode="json", by_alias=True, exclude_none=True) 
                   for model in processed_models]

# Task 3: F-Prefix Logic Refinement
def _extract_portfolio_code(input_model: AnnuityPerformanceIn, row_index: int) -> Optional[str]:
    """Extract portfolio code with selective F-prefix stripping."""
    if not input_model.组合代码:
        return None
        
    portfolio_code = str(input_model.组合代码).strip()
    
    # Only strip if it matches exact pattern ^F[0-9A-Z]+$
    if re.match(r'^F[0-9A-Z]+$', portfolio_code):
        return portfolio_code[1:]  # Remove leading 'F'
        
    return portfolio_code

# Keep _extract_plan_code separate and don't modify it based on portfolio context
def _extract_plan_code(input_model: AnnuityPerformanceIn, row_index: int) -> Optional[str]:
    """Extract plan code without F-prefix modification.""" 
    if input_model.计划代码:
        return str(input_model.计划代码).strip()
    return None
```

### Integration Points
```yaml
DATABASE:
  - DDL Update: Apply scripts/dev/annuity_performance_real.sql with auto-identity
  - Validation: Ensure GENERATED ALWAYS AS IDENTITY works with loader
  
CONFIG:
  - Primary Key: Continue using ["月度", "计划代码", "company_id"] in data_sources.yml
  - Column Mapping: Verify alias chain produces correct database column names
  
ORCHESTRATION:
  - JSON Handoff: Clean serialization without nulls or column name mismatches
  - Error Handling: Maintain existing error patterns and logging
```

## Validation Loop

### Level 1: Syntax & Style  
```bash
# Run these FIRST - fix any errors before proceeding
uv run ruff format .
uv run ruff check src/ --fix
uv run mypy src/

# Expected: No errors. If errors, READ the error and fix.
```

### Level 2: Unit Tests
```bash
# Run unit tests to verify domain logic changes:
uv run pytest tests/domain/annuity_performance/ -v

# Expected: All tests pass with updated assertions
# If failing: Check company_id updates and removed field assertions
```

### Level 3: Integration Tests - Plan Mode (Safe)
```bash
# Verify JSON serialization and SQL generation without DB execution
WDH_DATA_BASE_DIR=./reference/monthly \
  uv run python -m src.work_data_hub.orchestration.jobs \
  --domain annuity_performance --plan-only --max-files 1

# Expected Output Validation:
# 1. JSON contains aliased column names: "流失(含待遇支付)"
# 2. Generated SQL uses correct quoted identifiers
# 3. No column mismatch errors in plan generation
# 4. Primary key SQL includes ["月度", "计划代码", "company_id"]
```

### Level 4: Database Integration (Requires DDL)
```bash
# Apply DDL changes first:
psql "$WDH_DATABASE__URI" -f scripts/dev/annuity_performance_real.sql

# Execute full pipeline:
WDH_DATA_BASE_DIR=./reference/monthly \
  uv run python -m src.work_data_hub.orchestration.jobs \
  --domain annuity_performance --execute --max-files 1 --mode delete_insert

# Expected: Successful INSERT without providing ID values
# Expected: F-prefix stripping only applies to portfolio codes matching pattern
```

## Final Validation Checklist
- [ ] All tests pass: `uv run pytest -v`
- [ ] No linting errors: `uv run ruff check src/`
- [ ] No type errors: `uv run mypy src/`
- [ ] Plan mode shows aliased columns: `"流失(含待遇支付)"` in SQL
- [ ] Execute mode succeeds with auto-generated IDs
- [ ] F-prefix stripping is surgical (only portfolio codes matching ^F[0-9A-Z]+$)
- [ ] No column mismatch errors between JSON and database schema
- [ ] Tests use company_id and don't reference obsolete fields

---

## Anti-Patterns to Avoid
- ❌ Don't modify trustee domain serialization patterns unnecessarily
- ❌ Don't strip F-prefix from plan codes or non-matching patterns
- ❌ Don't hardcode ID values after implementing auto-identity
- ❌ Don't skip DDL application before execute mode testing
- ❌ Don't remove Chinese column quoting in PostgreSQL DDL
- ❌ Don't batch multiple changes without intermediate validation

## Confidence Score: 9/10

High confidence due to:
- Clear, specific requirements from INITIAL_en.md with precise acceptance criteria
- Well-understood codebase patterns and existing alias implementations
- Executable validation commands provided for each stage
- Research validates the technical approach (Pydantic serialization, PostgreSQL auto-identity)
- Surgical changes with minimal scope and clear rollback paths

Minor uncertainty only around edge cases in F-prefix pattern matching, but requirements specify exact regex pattern to eliminate ambiguity.