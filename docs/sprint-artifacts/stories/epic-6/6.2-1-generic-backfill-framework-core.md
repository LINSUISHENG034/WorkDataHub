# Story 6.2.1: Generic Backfill Framework Core

Status: done

## 五行摘要
- 目标：交付配置驱动、依赖有序的通用回填框架，覆盖 4/4 FK。
- 业务价值：消除 FK 约束失败、提升自动化，并提供可审计的数据质量追踪（auto_derived 可见）。
- 关键接口：`GenericBackfillService`（domain/reference_backfill/generic_service.py，BackfillResult 包含 processing_order/tables_processed/total_inserted）。
- 约束：遵循 AD-011 两层数据质量模型，依赖 YAML 配置 + DAG 排序，追踪列需由 6.2.2 迁移提供。
- 验证入口：`PYTHONPATH=src uv run python scripts/validation/verify_backfill_integrated.py`（期望 6/6 通过）。

## Epic Context & Dependencies
- Epic 6.2: Generic Reference Data Management（目标：配置驱动、依赖有序、含数据质量追踪的通用回填框架）。
- 关联故事：6.2.2（追踪列迁移）、6.2.3（data_sources.yml 外键配置模式）、6.2.4/6.2.5（预加载与混合策略后续整合）、6.2.6（可观测性）。本故事先行交付可运行的回填核心与配置模式，并为后续故事留出扩展点。
- 前置假设：Python 3.10+，pydantic 2.11.7，SQLAlchemy 2.0+，pandas 2.x；config/data_sources.yml 可被注入/验证；Dagster orchestration 已可加载 settings。
- 边界：不交付预加载服务与追踪列迁移（6.2.2 负责），仅定义/使用追踪字段；不修改非相关域。
- 业务价值（SCP-2025-12-12）：消除 FK 约束失败、提升自动化回填率，为数据治理提供 `_source/_needs_review` 可视化。
- 成功标准（AD-011）：4/4 FK 覆盖、零 FK 失败、auto_derived 可追踪、预加载覆盖率>90% 时仍可降级运行。

## Story

As a **data engineer**,
I want **a configuration-driven generic backfill framework**,
so that **new FK relationships can be handled without code changes**.

## Acceptance Criteria

### Functional Requirements

1. **FK Configuration in YAML（pydantic v2 schema）**
   - `config/data_sources.yml` 增加 `foreign_keys` 节点；每个 FK 含 `name`, `source_column`, `target_table`, `target_key`, `backfill_columns`（含 optional 标识）, `mode`, `depends_on`。
   - 使用 pydantic 2.11.7 校验（DomainForeignKeysConfig + ForeignKeyConfig + BackfillColumnMapping），校验失败需给出可读错误。

2. **Generic Derive Candidates（替换硬编码函数）**
   - 用 `derive_candidates(df, config)` 取代 `derive_plan_candidates()`/`derive_portfolio_candidates()`，按 `backfill_columns` 做列映射并去重、过滤空值。
   - 支持可选列（optional=true 时缺失不报错），缺少 `source_column` 时记录 warning 并跳过该 FK。

3. **All 4 FK Coverage**
   - 支持年金计划、组合计划、产品线、组织架构 4 个 FK；100% 覆盖。
   - FK 配置示例与默认值写入故事（见下文 Schema/配置示例）。

4. **Dependency Ordering**
   - 基于 `depends_on` 使用 `graphlib.TopologicalSorter`（Python 3.10 兼容）进行 DAG 排序；父表先于子表（年金计划 → 组合计划）。

5. **Backfill Service API 契约（domain 层）**
   - 新建 `GenericBackfillService`（`src/work_data_hub/domain/reference_backfill/generic_service.py`，由 `__init__.py` 导出）：`run(df: pd.DataFrame, configs: list[ForeignKeyConfig], conn, add_tracking_fields=True) -> BackfillResult`，内部调用 `_topological_sort`、`derive_candidates`、`backfill_table`。
   - `_topological_sort`：缺失依赖抛 `ValueError("...unknown key")`，循环依赖抛 `ValueError("Circular dependency...")`。
   - `backfill_table`：基于主键去重插入；默认写 tracking 字段；返回插入数。
   - 结果对象需包含 `processing_order`, `tables_processed[{table, inserted}]`, `total_inserted`，便于日志与测试断言。

6. **Dagster 集成与调用路径**
   - orchestration 层（src/work_data_hub/orchestration/ops.py 或相邻 op）改用 `GenericBackfillService`，并保持洁净依赖（domain 不引用 io/orchestration）。
   - 使用 settings/data_sources_config（Yaml）加载 FK 配置，沿用现有 Config 校验与日志模式；ops 保持参数化 domain。
   - pipe 调用需记录 processing_order、每表插入数；错误冒泡为 ValueError/自定义 DomainError。

7. **Config Schema 与版本兼容**
   - data_sources.yml schema 版本（现 1.0）在文档中说明：foreign_keys 为向后兼容新增字段；未配置时行为为 no-op。
   - 明确优先级：若配置缺失则跳过该域 FK backfill，但不报错；但缺必填字段时报错。

8. **DB Schema & Tracking 对齐**
   - 四张引用表主键：年金计划(年金计划号)、组合计划(组合代码)、产品线(产品线代码)、组织架构(组织代码)；示例 DDL/列要求列出。
   - 追踪列：`_source`(默认 authoritative)、`_needs_review`(bool, 默认 false)、`_derived_from_domain`(varchar)、`_derived_at`(timestamp)。插入 auto_derived 时必须覆盖为 auto_derived/true/domain/now()。

### Risk Mitigation（验证/安全/性能）

9. **Circular Dependency Detection**
   - 抛出包含循环路径的信息（ValueError），并被测试覆盖。

10. **Topological Sort Correctness**
    - 顺序满足 `depends_on`；提供 grandparent→parent→child 测试。

11. **Idempotency & Concurrency**
    - 重跑不重复插入（基于主键过滤）；单表插入使用事务或批量 upsert 前检查；支持串行 per-table，允许未来并行但需显式序列化。

12. **Data Source Tracking**
    - 插入记录强制设置 `_source='auto_derived'`, `_needs_review=True`, `_derived_from_domain=<domain>`, `_derived_at=<timestamp>`；时间戳使用 UTC；不覆盖已有记录。

13. **Performance Baseline**
    - ≥2,000 rows/sec（10K 数据集，SQLite/PG 均需在本地可达）；记录 `rows/sec`、batch size、连接池配置；插入前去重。

14. **Security & Compliance**
    - 仅使用 SQLAlchemy Core/ORM 参数化，禁止拼接 SQL；日志不含 PII/凭据；连接串来自 settings（不落盘）；权限最小化（仅 insert/select）。

15. **Error Reporting & Observability**
    - 日志包含 domain、processing_order、每表插入计数、跳过原因（缺列/无新值），以及异常明细；为后续指标上报预留 hook。

### Verification

16. **验证脚本**
    - `scripts/validation/verify_backfill_integrated.py` 全部 6/6 通过。

17. **新增测试**
    - 单元：配置校验、拓扑排序、循环检测、derive_candidates 可选列、backfill_table 幂等/追踪字段。
    - 集成：四 FK 全链路 + tracking 字段；性能基线（10K）；错误场景（缺列/缺依赖）。
    - Ops：调用路径 smoke（可用 mock/fixture 验证日志和处理顺序）。

## Tasks / Subtasks

- [x] Task 1: 配置模型（AC: #1, #7）
  - [x] 1.1 在 `domain/reference_backfill/models.py` 增加 BackfillColumnMapping / ForeignKeyConfig / DomainForeignKeysConfig（pydantic v2）。
  - [x] 1.2 错误信息友好化，覆盖缺字段/类型/未知 depends_on。
  - [x] 1.3 单测：配置校验成功/失败、未知依赖报错。

- [x] Task 2: 通用回填服务（AC: #2, #4, #5, #9, #10, #11, #12, #13, #14, #15）
  - [x] 2.1 `GenericBackfillService` 类实现 `_topological_sort`、`derive_candidates`（optional 列支持）、`backfill_table`（幂等+追踪字段）、`run`（返回 BackfillResult）。
  - [x] 2.2 循环/未知依赖抛 ValueError；缺 `source_column` 记录 warning 并跳过。
  - [x] 2.3 性能：批量插入策略（去重后批量写），记录 rows/sec。
  - [x] 2.4 日志与错误：结构化记录 processing_order/每表插入/跳过原因。

- [x] Task 3: 配置与示例（AC: #3, #8）
  - [x] 3.1 在 `config/data_sources.yml` 为 `annuity_performance` 添加 `foreign_keys`（四个 FK，全字段示例，depends_on 正确）。
  - [x] 3.2 说明 schema 版本兼容与默认行为（缺少 foreign_keys 时不执行回填）。

- [x] Task 4: 集成与复用（AC: #6, #11, #15）
  - [x] 4.1 orchestration ops 切换到 `GenericBackfillService`，保持依赖方向，保留 discover/read/loader 现有模式。
  - [x] 4.2 废弃旧函数 `derive_plan_candidates`/`derive_portfolio_candidates` 的调用路径（保留临时 shim 或直接替换）。
  - [x] 4.3 指定调用接口、参数与返回结构，增加日志/错误处理。

- [x] Task 5: 数据库与安全（AC: #8, #11, #14）
  - [x] 5.1 定义四张表的主键/必填/索引与追踪列写入规则（故事内 DDL 示例，代码中按列名写入）。
  - [x] 5.2 确保 SQLAlchemy 参数化、权限最小化、日志不含 PII/凭据。

- [x] Task 6: 测试与验证（AC: #16, #17）
  - [x] 6.1 维护/扩展 `scripts/validation/verify_backfill_integrated.py`（如需更新）并确保 6/6 通过。
  - [x] 6.2 单元/集成/性能测试新增：可选列、缺依赖、幂等、tracking 字段、ops 调用路径。
  - [x] 6.3 记录性能数字、处理顺序、插入计数。

## Dev Notes

### Architecture Decision Reference

**AD-011: Hybrid Reference Data Management Strategy** [Source: docs/architecture/architectural-decisions.md#Decision-11]

This story implements the **Generic Backfill Framework** component of the hybrid strategy:
- Two-layer data quality model (authoritative vs. auto-derived)
- Configuration-driven FK relationships
- Dependency-aware processing order via topological sort
- Source tracking for data governance

### Current Implementation Analysis

**Existing Code Location:** `src/work_data_hub/domain/reference_backfill/`

**Current State (to be replaced):**
- `service.py`: Contains hardcoded `derive_plan_candidates()` and `derive_portfolio_candidates()` functions
- `models.py`: Contains `AnnuityPlanCandidate` and `PortfolioCandidate` Pydantic models
- Coverage: Only 2/4 FKs (年金计划, 组合计划) - missing 产品线 and 组织架构
- orchestration/ops: 直接调用上述硬编码函数，未注入配置驱动行为

**Target State:**
- Generic `GenericBackfillService` class with configuration-driven behavior
- New Pydantic models: `ForeignKeyConfig`, `BackfillColumnMapping`, `DomainForeignKeysConfig`
- Coverage: All 4/4 FKs via configuration
- orchestration/ops 注入新服务和配置，保持分层与日志模式一致

### Previous Story Learnings & Reuse

- 沿用 Story 1.6 的 Clean Architecture 边界（ruff banned imports 已配置），domain 不得依赖 io/orchestration。
- 复用现有 ops 的日志/Config 结构和 DataSourceConnector + warehouse_loader 模式，避免重复实现 I/O。
- 遵循 pyproject 的 mypy 严格配置与 ruff 规则；新增代码需类型完全标注。
- 性能参考验证脚本基线（10K ≈ 148k rows/sec 为上限，≥2k rows/sec 为门槛），保持批量写入与去重。

### Technical Implementation Guidance

**Versions & Dependencies**

- Python ≥3.10；pydantic 2.11.7；SQLAlchemy ≥2.0；pandas 2.x；PyYAML；graphlib.TopologicalSorter（标准库）。
- 配置入口：`config/data_sources.yml`（schema_version: 1.0，向后兼容新增字段 `foreign_keys`）。
- 设置入口：`work_data_hub.config.settings.get_settings()` 提供 data_sources_config 路径与 DB 连接串；禁止在 domain 层读取 env。
- 最新兼容性检查（2025-12-12）：pydantic 2.11.7（已在 2.11.x 内稳定，无破坏性变更）；SQLAlchemy 2.0 系列当前接口稳定；graphlib 为标准库，无额外约束。升级策略：保持次要版本锁定（pydantic<3，SQLAlchemy<2.1）并在 verify_backfill_integrated 通过后再放宽。

**1. Pydantic Models (models.py)**

```python
from typing import List, Literal, Optional
from pydantic import BaseModel, Field

class BackfillColumnMapping(BaseModel):
    source: str = Field(..., description="Fact data column")
    target: str = Field(..., description="Reference table column")
    optional: bool = Field(default=False)

class ForeignKeyConfig(BaseModel):
    name: str
    source_column: str
    target_table: str
    target_key: str
    backfill_columns: List[BackfillColumnMapping]
    mode: Literal["insert_missing", "fill_null_only"] = "insert_missing"
    depends_on: List[str] = Field(default_factory=list)

class DomainForeignKeysConfig(BaseModel):
    foreign_keys: List[ForeignKeyConfig] = Field(default_factory=list)
```

**Schema & Tracking Fields (完整 DDL 定义)**

| 表 | 主键 | 追踪列（默认） | 索引 |
|---|---|---|---|
| 年金计划 | 年金计划号 | `_source varchar(20) not null default 'authoritative'`；`_needs_review bool not null default false`；`_derived_from_domain varchar(50)`；`_derived_at timestamptz` | `_source`，`_needs_review` |
| 组合计划 | 组合代码 | 同上；FK 年金计划号 | `_source`，`_needs_review`，`年金计划号` |
| 产品线 | 产品线代码 | 同上 | `_source`，`_needs_review` |
| 组织架构 | 组织代码 | 同上 | `_source`，`_needs_review` |

- 插入规则：authoritative 使用默认值；auto_derived 必须显式设置 `_source='auto_derived', _needs_review=true, _derived_from_domain=<domain>, _derived_at=utc_now()`。
- 6.2.2 协同：追踪列与索引由 6.2.2 迁移落地；若列未迁移且运行 add_tracking_fields=True，应先执行迁移或用 feature flag 关闭追踪列写入。

**2. Topological Sort Implementation**

```python
from graphlib import TopologicalSorter, CycleError

def _topological_sort(self, configs: List[ForeignKeyConfig]) -> List[ForeignKeyConfig]:
    name_map = {c.name: c for c in configs}
    graph = {c.name: set(c.depends_on) for c in configs}

    # Validate dependencies exist
    for name, deps in graph.items():
        for dep in deps:
            if dep not in name_map:
                raise ValueError(f"FK '{name}' depends on unknown key '{dep}'")

    sorter = TopologicalSorter(graph)
    try:
        sorted_names = list(sorter.static_order())
    except CycleError as e:
        raise ValueError(f"Circular dependency detected: {e}")

    return [name_map[name] for name in sorted_names]
```
- 异常示例：未知依赖 → `ValueError("FK 'fk_portfolio' depends on unknown key 'fk_plan_v2'")`；循环依赖 → `ValueError("Circular dependency detected: ('fk_plan', 'fk_portfolio', 'fk_plan')")`。

**3. Service Contract & Integration**

```python
from dataclasses import dataclass

@dataclass
class BackfillResult:
    processing_order: list[str]
    tables_processed: list[dict[str, int]]
    total_inserted: int

class GenericBackfillService:
    def run(self, df: pd.DataFrame, configs: list[ForeignKeyConfig], conn, add_tracking_fields: bool = True) -> BackfillResult: ...
    def derive_candidates(self, df: pd.DataFrame, config: ForeignKeyConfig) -> pd.DataFrame: ...
    def _topological_sort(self, configs: list[ForeignKeyConfig]) -> list[ForeignKeyConfig]: ...
    def backfill_table(self, candidates: pd.DataFrame, config: ForeignKeyConfig, conn, add_tracking_fields: bool = True) -> int: ...
```

- orchestration/ops：用 settings.data_sources_config 读取 YAML → pydantic 校验 → 注入 GenericBackfillService。保持 “domain 不依赖 io/orchestration”；ops 负责 I/O、日志、错误冒泡（ValueError/自定义 DomainError）。示例：`result = generic_backfill_service.run(df, configs, conn, add_tracking_fields=True)`；记录 `result.processing_order` 与每表插入计数。
- 复用 `work_data_hub.io.loader.warehouse_loader` 的 insert_missing/fill_null_only（若适用），保持依赖方向与命名规范。
- 并发/事务：每表串行、事务粒度单表，避免重复插入；未来并行需显式锁/序列化。推荐 READ COMMITTED，写前去重，失败重试应以幂等数据为前提。

**4. FK Configuration Schema (data_sources.yml)**

```yaml
domains:
  annuity_performance:
    # ... existing config ...
    foreign_keys:
      - name: "fk_plan"
        source_column: "计划代码"
        target_table: "年金计划"
        target_key: "年金计划号"
        backfill_columns:
          - source: "计划代码"
            target: "年金计划号"
          - source: "计划名称"
            target: "计划名称"
            optional: true
      - name: "fk_portfolio"
        source_column: "组合代码"
        target_table: "组合计划"
        target_key: "组合代码"
        depends_on: ["fk_plan"]
        backfill_columns:
          - source: "组合代码"
            target: "组合代码"
          - source: "计划代码"
            target: "年金计划号"
      - name: "fk_product_line"
        source_column: "产品线代码"
        target_table: "产品线"
        target_key: "产品线代码"
        backfill_columns:
          - source: "产品线代码"
            target: "产品线代码"
      - name: "fk_organization"
        source_column: "组织代码"
        target_table: "组织架构"
        target_key: "组织代码"
        backfill_columns:
          - source: "组织代码"
            target: "组织代码"
```

**5. Security / Idempotency / Observability**

- SQL 仅参数化；禁用字符串拼接；最小权限（select/insert），连接串只经 settings 注入，不落盘。
- 幂等：插入前拉取主键去重，事务粒度单表；重跑安全，允许 future 并行需显式序列化。
- 可观测性：日志包含 domain、processing_order、每表插入/跳过/耗时、rows/sec，异常明细；记录 UTC 时间。
- 性能：批量写入（去重后），记录 batch size 与连接池配置；10K ≥ 2,000 rows/sec。

### Migration Strategy

**Context:** New Pipeline (Dagster-based) is NOT yet in production. Clean replacement approach.

| Component | Current State | Target State | Action |
|-----------|---------------|--------------|--------|
| `derive_plan_candidates()` | Hardcoded function | Configuration-driven | **Replace** |
| `derive_portfolio_candidates()` | Hardcoded function | Configuration-driven | **Replace** |
| `BackfillService` class | Domain-specific | `GenericBackfillService` | **Replace** |
| Pipeline ops | Calls specific functions | Calls generic service | **Refactor** |
| `data_sources.yml` | No FK config | Add `foreign_keys` section | **Extend** |

**Rollback Plan:** Git-based rollback to previous commit if issues arise.

### Deployment / Ops Notes

- 运行入口：Dagster ops（orchestration 层）读取 settings.data_sources_config 与 DB 连接；保持现有 logging/Config 模式；禁用在 domain 层直接访问 env。
- 并发：每表串行处理；若 Dagster 并行 job 需显式序列化/锁，避免重复插入。
- 失败与重试：ValueError 直接失败；数据库错误需记录表名/批次，并可通过重跑实现补偿（幂等保障）。
- 观测：日志采集 processing_order、插入计数、rows/sec、跳过原因；为后续 metrics/alert 留出 hook。
- 回退：切换回旧函数时需移除新 ops 调用或用 feature flag 控制；配置未包含 foreign_keys 时自动 no-op。

### Project Structure Notes

**Files to Create/Modify:**

| File | Action | Purpose |
|------|--------|---------|
| `domain/reference_backfill/models.py` | **Extend** | Add FK config Pydantic models |
| `domain/reference_backfill/generic_service.py` | **Major** | Host GenericBackfillService |
| `config/data_sources.yml` | **Extend** | Add `foreign_keys` configuration |
| `tests/unit/domain/reference_backfill/` | **Add** | Unit tests for new service |

**Alignment with Unified Project Structure:**
- Models in `models.py` following existing pattern
- Service class在 `generic_service.py`（由 `__init__.py` 导出），保持 domain 位置
- Configuration in `config/data_sources.yml` following AD-010 pattern

### Testing Requirements

**Unit Tests:**
- `test_fk_config_validation.py` - Pydantic model validation
- `test_topological_sort.py` - Dependency ordering
- `test_circular_dependency.py` - Cycle detection
- `test_derive_candidates.py` - Generic candidate derivation
- `test_tracking_fields.py` - Data source tracking

**Integration Tests:**
- `test_all_four_fks.py` - End-to-end with all 4 FKs
- `test_performance.py` - Performance baseline verification

**Verification Script:**
- `scripts/validation/verify_backfill_integrated.py` - All 6 tests must pass
- 运行示例：`PYTHONPATH=src uv run python scripts/validation/verify_backfill_integrated.py`

### Performance Requirements

| Metric | Requirement | Verification |
|--------|-------------|--------------|
| Batch insert throughput | ≥2,000 rows/sec | 10K row test in verify script |
| Memory usage | No OOM on 100K rows | Manual verification |
| Topological sort | O(V+E) complexity | graphlib guarantees |

### References

- [Source: docs/sprint-artifacts/sprint-change-proposal/sprint-change-proposal-2025-12-12-generic-reference-management.md] - Full Sprint Change Proposal
- [Source: docs/architecture/architectural-decisions.md#Decision-11] - AD-011: Hybrid Reference Data Management
- [Source: scripts/validation/verify_backfill_integrated.py] - Technical verification script (6/6 tests passed)
- [Source: src/work_data_hub/domain/reference_backfill/generic_service.py] - Current implementation

### Git Intelligence

**Recent Commits (patterns to follow):**
- `a789e6b` - docs(epic-6.2): approve sprint change proposal
- `6fd3da0` - refactor(config): centralize domain output table configuration
- `3ca3f94` - feat(story-6.1.2): implement layer 2 multi-priority lookup

**Commit Message Pattern:** `feat(story-6.2.1): implement generic backfill framework core`

## Dev Agent Record

### Context Reference

- Sprint Change Proposal: `docs/sprint-artifacts/sprint-change-proposal/sprint-change-proposal-2025-12-12-generic-reference-management.md`
- Architecture Decision: `docs/architecture/architectural-decisions.md#Decision-11`
- Verification Script: `scripts/validation/verify_backfill_integrated.py`

### Agent Model Used

Claude Opus 4.5 (claude-opus-4-5-20251101)

### Debug Log References

- Unit tests: 32/32 passed
- Verification script: 6/6 passed
- Performance: 171,315 rows/sec (10K dataset)

### Completion Notes List

- Fixed derive_candidates logic bug that incorrectly filtered records with all-null optional columns
- Fixed test assertions for Pydantic v2 error message format changes
- Fixed Mock connection tests to use MagicMock for dialect attribute support

### File List

| File | Action | Description |
|------|--------|-------------|
| `src/work_data_hub/domain/reference_backfill/models.py` | Modified | Added BackfillColumnMapping, ForeignKeyConfig, DomainForeignKeysConfig Pydantic models |
| `src/work_data_hub/domain/reference_backfill/generic_service.py` | Created | GenericBackfillService with topological sort, derive_candidates, backfill_table, tracking fields |
| `src/work_data_hub/domain/reference_backfill/config_loader.py` | Created | Configuration loader for foreign_keys from data_sources.yml |
| `src/work_data_hub/domain/reference_backfill/__init__.py` | Modified | Exported new classes and functions |
| `src/work_data_hub/orchestration/ops.py` | Modified | Added generic_backfill_refs_op and GenericBackfillConfig |
| `config/data_sources.yml` | Modified | Added foreign_keys configuration for annuity_performance domain (4 FKs) |
| `docs/sprint-artifacts/sprint-status.yaml` | Modified | Updated Epic 6.2 story status entries |
| `docs/sprint-artifacts/stories/6.2-1-generic-backfill-framework-core.md` | Modified | Story content/status updates |
| `tests/unit/domain/reference_backfill/test_fk_config_validation.py` | Created | Unit tests for Pydantic configuration models |
| `tests/unit/domain/reference_backfill/test_generic_backfill_service.py` | Created | Unit tests for GenericBackfillService |
