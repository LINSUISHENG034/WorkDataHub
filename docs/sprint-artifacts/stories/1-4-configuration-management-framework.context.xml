<story-context id=".bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>1.4</storyId>
    <title>Configuration Management Framework</title>
    <status>drafted</status>
    <generatedAt>2025-11-10</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>.bmad-ephemeral/stories/1-4-configuration-management-framework.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>data engineer</asA>
    <iWant>centralized configuration loaded from environment variables with validation</iWant>
    <soThat>I avoid duplicating `os.getenv()` calls and catch missing config early</soThat>
    <tasks>
      - Task 1: Implement Settings model with Pydantic BaseSettings (AC: 1, 2, 3, 4)
        - Subtask 1.1: Create `src/work_data_hub/config/settings.py` with Pydantic `BaseSettings` class
        - Subtask 1.2: Add custom validator `@validator('DATABASE_URL')` to check PostgreSQL URL format when `ENVIRONMENT='prod'`
        - Subtask 1.3: Configure `class Config` with `env_file = ".env"` for automatic `.env` file loading
      - Task 2: Implement singleton pattern (AC: 5, 6)
        - Subtask 2.1: Create `get_settings()` function with `@lru_cache()` decorator
        - Subtask 2.2: Update `src/work_data_hub/config/__init__.py` to export `get_settings` and pre-instantiate `settings`
      - Task 3: Integrate with Story 1.3 logging (AC: 7)
        - Subtask 3.1: Update `src/work_data_hub/utils/logging.py` to import settings and use `settings.LOG_LEVEL`
        - Subtask 3.2: Document integration pattern
      - Task 4: Create comprehensive unit tests (AC: 8)
        - Subtask 4.1: Write test `test_missing_database_url_raises_error`
        - Subtask 4.2: Write test `test_production_requires_postgresql`
        - Subtask 4.3: Write test `test_settings_singleton`
        - Subtask 4.4: Mark all tests with `@pytest.mark.unit` marker
      - Task 5: Document configuration in README (AC: implied)
        - Subtask 5.1: Add section to README.md documenting all environment variables
        - Subtask 5.2: Update `.env.example` with new configuration variables
    </tasks>
  </story>

  <acceptanceCriteria>
    1. **Settings Module Implemented** – `src/work_data_hub/config/settings.py` exists with `Settings(BaseSettings)` class using Pydantic v2.
    2. **Required Fields Validated** – Settings model includes required fields: `DATABASE_URL: str`, `ENVIRONMENT: Literal["dev", "staging", "prod"]` and raises `ValidationError` if missing.
    3. **Optional Fields with Defaults** – Settings includes optional fields: `LOG_LEVEL: str = "INFO"`, `DAGSTER_HOME: str = "~/.dagster"`, `MAX_WORKERS: int = 4`, `DB_POOL_SIZE: int = 10`, `DB_BATCH_SIZE: int = 1000`.
    4. **Environment Variable Validation** – `Settings()` raises `ValidationError` with clear message when required `DATABASE_URL` missing or when `ENVIRONMENT=production` and `DATABASE_URL` is not a PostgreSQL connection string.
    5. **Singleton Pattern** – `get_settings()` function uses `@lru_cache()` decorator to return cached instance; multiple calls return same object without re-parsing environment variables.
    6. **Settings Accessible Project-Wide** – `src/work_data_hub/config/__init__.py` exports `get_settings` and pre-instantiated `settings` singleton for easy import: `from config import settings`.
    7. **Logging Integration** – `utils/logging.py` uses `settings.LOG_LEVEL` to configure log level, demonstrating integration with Story 1.3 structured logging.
    8. **Unit Tests Pass** – Tests verify: missing required field raises `ValidationError`, production environment validates PostgreSQL URL format, settings singleton returns same instance on multiple calls.
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>FR-7: Configuration Management</section>
        <snippet>Enforces YAML-based domain config and environment-specific settings for dev vs. production. Configuration must be externalized from code with validation on startup.</snippet>
      </doc>
      <doc>
        <path>docs/tech-spec-epic-1.md</path>
        <title>Technical Specification - Epic 1</title>
        <section>Story 1.4: Configuration Management</section>
        <snippet>Comprehensive technical specification for Settings model structure, required/optional fields (AC-1.4.1 through AC-1.4.6), singleton pattern with @lru_cache(), logging integration, and testing requirements. Includes code examples and validation patterns.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>System Architecture Document</title>
        <section>Decision #7: Comprehensive Naming Conventions</section>
        <snippet>Specifies UPPER_SNAKE_CASE for environment variables (e.g., DATABASE_URL, LOG_LEVEL). Configuration layer belongs in config/ module following Clean Architecture boundaries.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Story 1.4: Configuration Management Framework</section>
        <snippet>Story prerequisites (Story 1.3 logging), technical notes on Pydantic BaseSettings usage, custom validators for production PostgreSQL validation, and configuration documentation requirements.</snippet>
      </doc>
      <doc>
        <path>docs/stories/1-3-structured-logging-framework.md</path>
        <title>Story 1.3: Structured Logging Framework (Completed)</title>
        <section>Dev Notes</section>
        <snippet>Established pattern for environment-driven configuration with LOG_LEVEL, LOG_TO_FILE, LOG_FILE_DIR. Integration point identified: utils/logging.py currently reads environment variables directly and should be updated to use settings.LOG_LEVEL.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/work_data_hub/config/__init__.py</path>
        <kind>module</kind>
        <symbol>N/A (currently empty)</symbol>
        <lines>entire file</lines>
        <reason>Target file for exporting get_settings() function and settings singleton. Currently empty, needs implementation per AC-6.</reason>
      </artifact>
      <artifact>
        <path>src/work_data_hub/utils/logging.py</path>
        <kind>utility module</kind>
        <symbol>_get_log_level</symbol>
        <lines>93-96</lines>
        <reason>Integration point: Currently uses os.getenv("LOG_LEVEL", "INFO") directly. Should be updated to use settings.LOG_LEVEL from new Settings class per AC-7.</reason>
      </artifact>
      <artifact>
        <path>tests/config/test_settings_env.py</path>
        <kind>test</kind>
        <symbol>N/A (existing file)</symbol>
        <lines>entire file</lines>
        <reason>Existing test file in tests/config/ directory. Can be expanded with new Settings model tests per AC-8.</reason>
      </artifact>
      <artifact>
        <path>tests/unit/utils/test_logging.py</path>
        <kind>test</kind>
        <symbol>N/A (existing file)</symbol>
        <lines>entire file</lines>
        <reason>Existing logging tests. May need update after integrating settings.LOG_LEVEL to verify integration works correctly.</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <package name="pydantic" version=">=2.11.7"/>
        <package name="pydantic-settings" version=">=2.10.1"/>
        <package name="python" version=">=3.10"/>
      </python>
    </dependencies>
  </artifacts>

  <constraints>
    - Use Pydantic BaseSettings exactly as shown in tech spec for automatic .env loading and type validation
    - Implement custom @validator('DATABASE_URL') to prevent SQLite usage in production (prevents accidental data loss)
    - Singleton pattern via @lru_cache() ensures configuration loaded exactly once at startup without performance penalty
    - Environment variable naming follows Decision #7: UPPER_SNAKE_CASE (e.g., DATABASE_URL, LOG_LEVEL)
    - Must pass mypy --strict mode validation with explicit type hints on all Settings fields
    - Configuration loaded from .env file which must be gitignored (security requirement)
    - Settings validation must prevent runtime failures by catching missing/invalid config at startup
    - Integration with Story 1.3 logging framework demonstrates settings pattern works correctly
  </constraints>

  <interfaces>
    <interface>
      <name>Settings</name>
      <kind>Pydantic BaseSettings class</kind>
      <signature>class Settings(BaseSettings):
    DATABASE_URL: str
    ENVIRONMENT: Literal["dev", "staging", "prod"] = "dev"
    LOG_LEVEL: str = "INFO"
    DAGSTER_HOME: str = "~/.dagster"
    MAX_WORKERS: int = 4
    DB_POOL_SIZE: int = 10
    DB_BATCH_SIZE: int = 1000

    class Config:
        env_file = ".env"</signature>
      <path>src/work_data_hub/config/settings.py (to be created)</path>
    </interface>
    <interface>
      <name>get_settings</name>
      <kind>Singleton factory function</kind>
      <signature>@lru_cache()
def get_settings() -> Settings:
    """Return cached Settings instance."""
    return Settings()</signature>
      <path>src/work_data_hub/config/settings.py (to be created)</path>
    </interface>
    <interface>
      <name>_get_log_level (integration point)</name>
      <kind>Logging utility function</kind>
      <signature>def _get_log_level() -> int:
    """Get log level from environment variable."""
    # CURRENT: level_name = os.getenv("LOG_LEVEL", "INFO").upper()
    # SHOULD BE: level_name = settings.LOG_LEVEL.upper()</signature>
      <path>src/work_data_hub/utils/logging.py (to be updated)</path>
    </interface>
  </interfaces>

  <tests>
    <standards>Tests follow Story 1.2 CI requirements: marked with @pytest.mark.unit for fast execution, run via `uv run pytest -v -m unit`, must pass mypy --strict mode validation. Use pytest.MonkeyPatch for environment variable isolation to prevent test interference. Tests stored in tests/config/ directory following project structure.</standards>
    <locations>
      - tests/config/ (unit tests for config module)
      - tests/unit/utils/ (integration tests for logging with settings)
    </locations>
    <ideas>
      - AC-2, AC-4: test_missing_database_url_raises_error() - Verify ValidationError when DATABASE_URL not set in environment
      - AC-4: test_production_requires_postgresql() - Verify ValidationError when ENVIRONMENT='prod' with non-PostgreSQL URL (e.g., sqlite://)
      - AC-5: test_settings_singleton() - Verify get_settings() returns same instance on multiple calls (id() check)
      - AC-3: test_optional_fields_defaults() - Verify LOG_LEVEL="INFO", MAX_WORKERS=4, etc. when not set in environment
      - AC-7: test_logging_integration() - Import settings in logging module and verify LOG_LEVEL configuration works
      - AC-6: test_settings_import_patterns() - Verify both import patterns work: `from config import settings` and `from config import get_settings`
      - AC-1: test_settings_model_structure() - Verify Settings class exists with all required and optional fields
      - AC-4: test_custom_validator_postgresql() - Test DATABASE_URL validator accepts valid PostgreSQL URLs and rejects invalid formats
    </ideas>
  </tests>
</story-context>
